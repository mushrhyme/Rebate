"""
img í´ë”ì˜ PDF ë°ì´í„°ë¥¼ FAISS ë²¡í„° DBë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ (ì¦ë¶„ shard + merge êµ¬ì¡°)

img í´ë”ì˜ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ:
- PDF íŒŒì¼ (PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
- Page*_answer.json (ì •ë‹µ JSON)

íŒŒì¼ì„ ì°¾ì•„ì„œ ë³€ê²½ë¶„ë§Œ shardë¡œ ìƒì„±í•˜ê³  base DBì— mergeí•©ë‹ˆë‹¤.
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
import fitz  # PyMuPDF

from modules.core.rag_manager import get_rag_manager
from modules.utils.config import get_project_root
from modules.utils.hash_utils import compute_page_hash, get_page_key, compute_file_fingerprint
from modules.utils.db_manifest_manager import DBManifestManager
from modules.utils.pdf_utils import PdfTextExtractor
from modules.utils.pdf_to_excel import PdfToExcelConverter


def find_pdf_pages(
    img_dir: Path,
    form_folder: Optional[str] = None,
) -> List[Dict[str, Any]]:
    """
    img í´ë”ì˜ ì–‘ì‹ë³„ í´ë”(01, 02 ë“±) ì•ˆì˜ í•˜ìœ„ í´ë”ì—ì„œ ëª¨ë“  PDF í˜ì´ì§€ ë°ì´í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

    Args:
        img_dir: img í´ë” ê²½ë¡œ
        form_folder: ì–‘ì‹ í´ë”ëª… (ì˜ˆ: "01", "02"). Noneì´ë©´ ëª¨ë“  ì–‘ì‹ í´ë”ë¥¼ ìˆœíšŒ

    Returns:
        [page_data, ...] ë¦¬ìŠ¤íŠ¸
        page_data = {
            'pdf_name': str,
            'page_num': int,
            'pdf_path': Path,
            'answer_json_path': Optional[Path]
        }
    """
    pages = []

    # ì–‘ì‹ë³„ í´ë” ëª©ë¡ (01, 02, 03, 04, 05 ë“±)
    if form_folder:
        form_folders = [img_dir / form_folder]
    else:
        # ëª¨ë“  ì–‘ì‹ í´ë” ìˆœíšŒ
        form_folders = [d for d in img_dir.iterdir() if d.is_dir() and d.name.isdigit()]
        form_folders.sort()  # ìˆ«ì ìˆœì„œë¡œ ì •ë ¬

    for form_dir in form_folders:
        if not form_dir.exists():
            continue

        print(f"ğŸ“ ì–‘ì‹ í´ë”: {form_dir.name}")

        # ì–‘ì‹ í´ë” ì•ˆì˜ í•˜ìœ„ í´ë” ìˆœíšŒ
        for pdf_folder in form_dir.iterdir():
            if not pdf_folder.is_dir():
                continue

            pdf_name = pdf_folder.name
            pdf_file = pdf_folder / f"{pdf_name}.pdf"
            if not pdf_file.exists():
                pdf_file = form_dir / f"{pdf_name}.pdf"

            if not pdf_file.exists():
                print(f"  âš ï¸ PDF íŒŒì¼ ì—†ìŒ: {pdf_name}")
                continue

            # ë²„ì „ êµ¬ë¶„ ì—†ì´ ëª¨ë“  Page*_answer*.json ëŒ€ìƒìœ¼ë¡œ ì²˜ë¦¬
            answer_files = sorted(pdf_folder.glob("Page*_answer*.json"))

            if not answer_files:
                print(f"  âš ï¸ {pdf_name}: answer.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                continue

            try:
                doc = fitz.open(pdf_file)
                page_count = len(doc)
                doc.close()
            except Exception as e:
                print(f"  âš ï¸ PDF íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨ ({pdf_name}): {e}")
                continue

            print(f"  - {pdf_name}: {len(answer_files)}ê°œ answer.json íŒŒì¼, {page_count}í˜ì´ì§€")

            for answer_file in answer_files:
                try:
                    # Page{num}_answer.json ë˜ëŠ” Page{num}_answer_xx.json í˜•ì‹ ëŒ€ì‘
                    stem = answer_file.stem
                    # ê°€ì¥ ì™¼ìª½ì˜ ìˆ«ìë§Œ ë½‘ëŠ”ë‹¤. ì˜ˆì‹œ: Page3_answer_v2 -> '3'
                    import re
                    match = re.match(r'Page(\d+)_answer', stem)
                    if not match:
                        print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ íŒŒì‹± ì‹¤íŒ¨: {answer_file}")
                        continue
                    page_num = int(match.group(1))

                    if page_num < 1 or page_num > page_count:
                        print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ ë²”ìœ„ ì´ˆê³¼: {pdf_name} Page{page_num} (ìµœëŒ€: {page_count})")
                        continue

                    pages.append({
                        'pdf_name': pdf_name,
                        'page_num': page_num,
                        'pdf_path': pdf_file,
                        'answer_json_path': answer_file
                    })
                except ValueError:
                    print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ íŒŒì‹± ì‹¤íŒ¨: {answer_file}")
                    continue

    return pages




def load_answer_json(answer_path: Optional[Path]) -> Dict[str, Any]:
    """ì •ë‹µ JSON íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤."""
    if answer_path is None or not answer_path.exists():
        return {}

    try:
        with open(answer_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ ì •ë‹µ JSON ì½ê¸° ì‹¤íŒ¨ ({answer_path}): {e}")
        return {}


def diff_pages_with_manifest(
    pages: List[Dict[str, Any]],
    manifest: DBManifestManager,
    text_extractor: PdfTextExtractor,
    text_extraction_method: str = "pymupdf"  # "pymupdf" ë˜ëŠ” "excel"
) -> List[Dict[str, Any]]:
    """
    manifestì™€ ë¹„êµí•˜ì—¬ ìƒˆë¡œìš´ í˜ì´ì§€ ë˜ëŠ” ë³€ê²½ëœ í˜ì´ì§€ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    2ë‹¨ê³„ ì²´í¬: 1ë‹¨ê³„(answer.json fingerprint) â†’ 2ë‹¨ê³„(ì‹¤ì œ í…ìŠ¤íŠ¸ hash)
    staged ìƒíƒœëŠ” ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ.

    Args:
        pages: í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        manifest: DBManifestManager ì¸ìŠ¤í„´ìŠ¤
        text_extractor: PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° (ìºì‹± ì§€ì›)

    Returns:
        ìƒˆë¡œìš´ í˜ì´ì§€ ë˜ëŠ” ë³€ê²½ëœ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
    """
    new_pages = []

    for page_data in pages:
        pdf_name = page_data['pdf_name']
        page_num = page_data['page_num']
        pdf_path = page_data['pdf_path']
        answer_path = page_data.get('answer_json_path')

        if not answer_path or not answer_path.exists():
            continue

        pdf_filename = f"{pdf_name}.pdf"  # DBëŠ” í™•ì¥ì í¬í•¨
        page_key = get_page_key(pdf_name, page_num)

        # staged ìƒíƒœëŠ” ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
        if manifest.is_staged(pdf_filename, page_num):
            continue

        # 1ë‹¨ê³„: answer.json fingerprint ì²´í¬
        fingerprint = compute_file_fingerprint(pdf_path, answer_path)
        if not manifest.is_file_changed_fast(pdf_filename, page_num, fingerprint):
            continue

        # 2ë‹¨ê³„: ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° hash ê³„ì‚°
        if text_extraction_method == "excel":
            # ì—‘ì…€ ë³€í™˜ ë°©ë²• ì‚¬ìš©
            try:
                excel_converter = PdfToExcelConverter(method="pdfplumber")
                ocr_text = excel_converter.convert_to_text_for_llm(pdf_path, page_num)
            except Exception as e:
                print(f"âš ï¸ ì—‘ì…€ ë³€í™˜ ì‹¤íŒ¨, PyMuPDFë¡œ í´ë°± ({pdf_name}, í˜ì´ì§€ {page_num}): {e}")
                ocr_text = text_extractor.extract_text(pdf_path, page_num)
        else:
            # ê¸°ë³¸ PyMuPDF ë°©ë²• ì‚¬ìš©
            ocr_text = text_extractor.extract_text(pdf_path, page_num)

        if not ocr_text:
            continue

        answer_json = load_answer_json(answer_path)
        if not answer_json:
            continue

        page_hash = compute_page_hash(ocr_text, answer_json)

        # merged ìƒíƒœì´ê³  hash ë™ì¼í•˜ë©´ ìŠ¤í‚µ
        if manifest.is_processed(pdf_filename, page_num, page_hash):
            continue

        # ìƒˆë¡œìš´ í˜ì´ì§€ì´ê±°ë‚˜ ë³€ê²½ë¨
        new_pages.append({
            **page_data,
            'ocr_text': ocr_text,
            'answer_json': answer_json,
            'page_hash': page_hash,
            'page_key': page_key,
            'fingerprint': fingerprint,
            'pdf_filename': pdf_filename  # DBìš© íŒŒì¼ëª… ì¶”ê°€
        })

    return new_pages


def detect_deleted_pages(
    scanned_pages: List[Dict[str, Any]],  # [{'pdf_name': str, 'page_num': int}, ...]
    manifest: DBManifestManager
) -> List[Dict[str, Any]]:
    """
    ì‚­ì œëœ í˜ì´ì§€ ê°ì§€ (manifestì— ìˆì§€ë§Œ ìŠ¤ìº” ê²°ê³¼ì— ì—†ìŒ)

    Args:
        scanned_pages: í˜„ì¬ ìŠ¤ìº”ëœ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
        manifest: DBManifestManager ì¸ìŠ¤í„´ìŠ¤

    Returns:
        ì‚­ì œëœ í˜ì´ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{'pdf_filename': str, 'page_number': int}, ...]
    """
    # ìŠ¤ìº”ëœ í˜ì´ì§€ë¥¼ (pdf_filename, page_number) ì§‘í•©ìœ¼ë¡œ ë³€í™˜
    scanned_set = {
        (f"{p['pdf_name']}.pdf", p['page_num'])
        for p in scanned_pages
    }

    # DBì—ì„œ ëª¨ë“  í˜ì´ì§€ ì¡°íšŒ
    try:
        with manifest.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT pdf_filename, page_number, status
                FROM rag_learning_status
                WHERE status IN ('merged', 'staged')
            """)

            deleted_pages = []
            for row in cursor.fetchall():
                pdf_filename = row[0]
                page_number = row[1]
                status = row[2]

                # ìŠ¤ìº” ê²°ê³¼ì— ì—†ìœ¼ë©´ ì‚­ì œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                if (pdf_filename, page_number) not in scanned_set:
                    deleted_pages.append({
                        'pdf_filename': pdf_filename,
                        'page_number': page_number
                    })

        return deleted_pages
    except Exception as e:
        # í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        print(f"âš ï¸ ì‚­ì œëœ í˜ì´ì§€ ê°ì§€ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        return []


def build_faiss_db(
    img_dir: Path = None,
    form_folder: Optional[str] = None,
    auto_merge: bool = False,
    text_extraction_method: str = "pymupdf"  # "pymupdf" ë˜ëŠ” "excel"
) -> None:
    """
    img í´ë”ì˜ ë°ì´í„°ë¥¼ FAISS ë²¡í„° DBë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (ì¦ë¶„ shard + merge êµ¬ì¡°).

    Args:
        img_dir: img í´ë” ê²½ë¡œ (Noneì´ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸/img)
        form_folder: ì–‘ì‹ í´ë”ëª… (ì˜ˆ: "01", "02"). Noneì´ë©´ ëª¨ë“  ì–‘ì‹ í´ë”ë¥¼ ìˆœíšŒ
        auto_merge: shard ìƒì„± í›„ ìë™ìœ¼ë¡œ mergeí• ì§€ ì—¬ë¶€
        text_extraction_method: í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ("pymupdf" ë˜ëŠ” "excel")
            - "pymupdf": PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê¸°ë³¸ê°’)
            - "excel": pdfplumberë¡œ í…Œì´ë¸” ì¶”ì¶œ í›„ ì—‘ì…€ í˜•ì‹ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    """
    if img_dir is None:
        project_root = get_project_root()
        img_dir = project_root / "img"

    if not img_dir.exists():
        print(f"âŒ img í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_dir}")
        return

    if form_folder:
        print(f"ğŸ“‚ ì–‘ì‹ í´ë” '{form_folder}' ìŠ¤ìº” ì¤‘: {img_dir / form_folder}")
    else:
        print(f"ğŸ“‚ img í´ë”ì˜ ëª¨ë“  ì–‘ì‹ í´ë” ìŠ¤ìº” ì¤‘: {img_dir}")

    pages = find_pdf_pages(img_dir, form_folder)
    if not pages:
        print("âŒ ì²˜ë¦¬í•  í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"âœ… {len(pages)}ê°œ í˜ì´ì§€ ë°œê²¬\n")

    # RAG Manager ì´ˆê¸°í™”
    print("ğŸ”„ RAG Manager ì´ˆê¸°í™” ì¤‘...")
    try:
        rag_manager = get_rag_manager()
        print("âœ… RAG Manager ì´ˆê¸°í™” ì™„ë£Œ\n")
    except Exception as e:
        print(f"âŒ RAG Manager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # DB Manifest Manager ì´ˆê¸°í™”
    manifest = DBManifestManager()

    print(f"ğŸ“‹ DB Manifest ë¡œë“œ: {len(manifest.get_all_page_keys())}ê°œ í˜ì´ì§€ ë“±ë¡ë¨\n")

    # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ìƒì„± (ìºì‹± ì§€ì›)
    text_extractor = PdfTextExtractor()

    try:
        # ì‚­ì œëœ í˜ì´ì§€ ê°ì§€
        deleted_pages = detect_deleted_pages(pages, manifest)
        if deleted_pages:
            print(f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€ ê°ì§€: {len(deleted_pages)}ê°œ")
            for deleted in deleted_pages[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                print(f"   - {deleted['pdf_filename']} í˜ì´ì§€ {deleted['page_number']}")
            if len(deleted_pages) > 10:
                print(f"   ... ì™¸ {len(deleted_pages) - 10}ê°œ")
            manifest.mark_pages_deleted(deleted_pages)

        # manifestì™€ ë¹„êµí•˜ì—¬ ë³€ê²½ë¶„ë§Œ í•„í„°ë§
        print(f"ğŸ” Manifestì™€ ë¹„êµí•˜ì—¬ ë³€ê²½ë¶„ í™•ì¸ ì¤‘... (í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²•: {text_extraction_method})")
        new_pages = diff_pages_with_manifest(pages, manifest, text_extractor, text_extraction_method)

        if not new_pages:
            print("âœ… ë³€ê²½ëœ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  í˜ì´ì§€ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.\n")
            return

        print(f"ğŸ“ ë³€ê²½ëœ í˜ì´ì§€: {len(new_pages)}ê°œ ë°œê²¬\n")

        # ê¸°ì¡´ ì˜ˆì œ ìˆ˜ í™•ì¸
        existing_count = rag_manager.count_examples()
        print(f"ğŸ“Š ê¸°ì¡´ ë²¡í„° DB ì˜ˆì œ ìˆ˜: {existing_count}ê°œ\n")

        # shard ìƒì„±ì„ ìœ„í•œ í˜ì´ì§€ ë°ì´í„° ì¤€ë¹„
        shard_pages = []
        for page_data in new_pages:
            pdf_name = page_data['pdf_name']
            page_num = page_data['page_num']

            metadata = {
                'pdf_name': pdf_name,
                'page_num': page_num,
                'source': 'img_folder'
            }

            shard_pages.append({
                'pdf_name': pdf_name,
                'page_num': page_num,
                'ocr_text': page_data['ocr_text'],
                'answer_json': page_data['answer_json'],
                'metadata': metadata,
                'page_key': page_data['page_key'],
                'page_hash': page_data['page_hash']
            })

        # shard FAISS DB ìƒì„±
        print("ğŸ”¨ Shard ìƒì„± ì¤‘...")
        result = rag_manager.build_shard(shard_pages)

        if not result:
            print("âŒ Shard ìƒì„± ì‹¤íŒ¨")
            return

        # resultëŠ” (shard_path ë˜ëŠ” shard_index_name, shard_id) íŠœí”Œ
        shard_identifier, shard_id = result

        # shard ìƒì„± ì‹œ manifest ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (staged ìƒíƒœ)
        print("\nğŸ“‹ DB Manifestì— staged ìƒíƒœ ê¸°ë¡ ì¤‘...")
        page_hashes = {p['page_key']: p['page_hash'] for p in new_pages}
        fingerprints = {p['page_key']: p['fingerprint'] for p in new_pages}

        # DBìš© í˜ì´ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        db_pages = [
            {
                'pdf_filename': p['pdf_filename'],
                'page_number': p['page_num']
            }
            for p in new_pages
        ]

        manifest.mark_pages_staged(db_pages, shard_id, page_hashes, fingerprints)
        print(f"âœ… DB Manifest ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(db_pages)}ê°œ í˜ì´ì§€ staged ìƒíƒœë¡œ ê¸°ë¡\n")

        # shard â†’ base merge
        if auto_merge:
            print("ğŸ”„ Shardë¥¼ baseì— merge ì¤‘...")
            # shard_identifierëŠ” DB ëª¨ë“œì—ì„œëŠ” index_name, íŒŒì¼ ëª¨ë“œì—ì„œëŠ” íŒŒì¼ ê²½ë¡œ
            merge_success = rag_manager.merge_shard(shard_identifier)

            if merge_success:
                # merge ì„±ê³µ ì‹œ ìƒíƒœ ì „ì´ (staged â†’ merged)
                print("\nğŸ“‹ DB Manifest ìƒíƒœ ì „ì´ ì¤‘ (staged â†’ merged)...")
                manifest.mark_pages_merged(db_pages)
                print(f"âœ… DB Manifest ìƒíƒœ ì „ì´ ì™„ë£Œ: {len(db_pages)}ê°œ í˜ì´ì§€ merged ìƒíƒœë¡œ ë³€ê²½\n")
            else:
                print("âŒ Shard merge ì‹¤íŒ¨ (staged ìƒíƒœ ìœ ì§€)\n")
                return
        else:
            print(f"\nâš ï¸ ìë™ mergeê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            print(f"   ìˆ˜ë™ìœ¼ë¡œ mergeí•˜ë ¤ë©´: rag_manager.merge_shard('{shard_identifier}')\n")
            print(f"   merge í›„ manifest.mark_pages_merged(db_pages)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n")

        # ê²°ê³¼ ìš”ì•½
        print("="*60)
        print("ğŸ“Š ë²¡í„° DB êµ¬ì¶• ê²°ê³¼")
        print("="*60)
        print(f"âœ… ì²˜ë¦¬ëœ í˜ì´ì§€: {len(new_pages)}ê°œ")
        print(f"ğŸ“ˆ ê¸°ì¡´ ë²¡í„° DB ì˜ˆì œ ìˆ˜: {existing_count}ê°œ")
        print(f"ğŸ’¾ ìµœì¢… ë²¡í„° DB ì˜ˆì œ ìˆ˜: {rag_manager.count_examples()}ê°œ")
        print(f"ğŸ“‹ DB Manifest ë“±ë¡ í˜ì´ì§€ ìˆ˜: {len(manifest.get_all_page_keys())}ê°œ")
        if deleted_pages:
            print(f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€: {len(deleted_pages)}ê°œ")
        print("="*60)
    finally:
        # PDF ìºì‹œ ì •ë¦¬
        text_extractor.close_all()


if __name__ == "__main__":
    import sys
    print("ğŸš€ FAISS ë²¡í„° DB êµ¬ì¶• ì‹œì‘\n")

    # ëª…ë ¹ì¤„ ì¸ìë¡œ ì–‘ì‹ í´ë” ì§€ì • ê°€ëŠ¥
    form_folder = None
    if len(sys.argv) > 1:
        form_folder = sys.argv[1]
        print(f"ğŸ“ ì§€ì •ëœ ì–‘ì‹ í´ë”: {form_folder}\n")

    build_faiss_db(
        form_folder=form_folder,
        auto_merge=True,
        text_extraction_method="excel"  # ê¸°ë³¸ PyMuPDF ë°©ë²• (ì—‘ì…€ ë³€í™˜ì€ "excel")
    )
    print("\nâœ… ì™„ë£Œ!")
