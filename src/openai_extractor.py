"""
OpenAI Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ PDFë¥¼ í˜ì´ì§€ë³„ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë“ˆ

PDF íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ê³ , OpenAI Vision APIë¡œ ê° í˜ì´ì§€ë¥¼ ë¶„ì„í•˜ì—¬
êµ¬ì¡°í™”ëœ JSON ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. Gemini extractorì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import json
import re
import os
import time
import base64
from pathlib import Path
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

from pdf2image import convert_from_path
from PIL import Image, ImageFile
from openai import OpenAI

# DecompressionBombWarning ë°©ì§€: ì´ë¯¸ì§€ í¬ê¸° ì œí•œ ì¦ê°€
Image.MAX_IMAGE_PIXELS = None  # ì œí•œ ì—†ìŒ (ë˜ëŠ” ì¶©ë¶„íˆ í° ê°’ìœ¼ë¡œ ì„¤ì •)
ImageFile.LOAD_TRUNCATED_IMAGES = True  # ì†ìƒëœ ì´ë¯¸ì§€ë„ ë¡œë“œ ì‹œë„

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ì„ ëª…ì‹œì ìœ¼ë¡œ ë¡œë“œ
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path)  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ


class PDFProcessor:
    """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, dpi: int = 300):
        """
        Args:
            dpi: PDF ë³€í™˜ ì‹œ í•´ìƒë„ (ê¸°ë³¸ê°’: 300)
        """
        self.dpi = dpi
    
    def convert_pdf_to_images(self, pdf_path: str) -> List[Image.Image]:
        """
        PDF íŒŒì¼ì„ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸ (ê° í˜ì´ì§€ë‹¹ í•˜ë‚˜)
        """
        images = convert_from_path(pdf_path, dpi=self.dpi)  # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        return images
    
    def save_images(self, images: List[Image.Image], output_dir: str, prefix: str = "page") -> List[str]:
        """
        ì´ë¯¸ì§€ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            images: PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸
            output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            prefix: íŒŒì¼ëª… ì ‘ë‘ì‚¬ (ê¸°ë³¸ê°’: "page")
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        os.makedirs(output_dir, exist_ok=True)  # ë””ë ‰í† ë¦¬ ìƒì„±
        saved_paths = []
        
        for idx, img in enumerate(images):
            filename = f"{prefix}_{idx+1}.jpg"  # JPEG í˜•ì‹ìœ¼ë¡œ ì €ì¥
            filepath = os.path.join(output_dir, filename)
            try:
                # ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ê°•ì œë¡œ ë¡œë“œ
                img.load()
                # JPEGë¡œ ì €ì¥ (í’ˆì§ˆ 95ë¡œ ê³ í’ˆì§ˆ ìœ ì§€)
                # RGB ëª¨ë“œë¡œ ë³€í™˜ (JPEGëŠ” RGBë§Œ ì§€ì›)
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                img.save(filepath, "JPEG", quality=95, optimize=True)
                # ì €ì¥ëœ íŒŒì¼ì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
                    saved_paths.append(filepath)
                else:
                    print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {filepath} (íŒŒì¼ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤)")
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({filepath}): {e}")
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                if os.path.exists(filepath):
                    saved_paths.append(filepath)
        
        return saved_paths


class OpenAIVisionParser:
    """OpenAI Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ íŒŒì‹±"""
    
    def __init__(self, api_key: Optional[str] = None, model_name: str = "gpt-5-mini-2025-08-07", prompt_version: str = "v2"):
        """
        Args:
            api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
            model_name: ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: "gpt-5-mini-2025-08-07")
            prompt_version: í”„ë¡¬í”„íŠ¸ ë²„ì „ (ê¸°ë³¸ê°’: "v2", prompts/prompt_v2.txt íŒŒì¼ ì‚¬ìš©)
        """
        if api_key is None:
            api_key = os.getenv("OPENAI_API_KEY")  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
            if not api_key:
                raise ValueError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•˜ì„¸ìš”.")
        
        self.client = OpenAI(api_key=api_key)  # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.model_name = model_name
        self.prompt_version = prompt_version  # í”„ë¡¬í”„íŠ¸ ë²„ì „ ì €ì¥
    
    def get_parsing_prompt(self) -> str:
        """
        OpenAI Visionì„ ìœ„í•œ êµ¬ì¡°í™” íŒŒì‹± í”„ë¡¬í”„íŠ¸
        
        Returns:
            íŒŒì‹± í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ ìƒì„±
        prompt_file = Path(__file__).parent.parent / "prompts" / f"prompt_{self.prompt_version}.txt"
        
        # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì½ê¸°, ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if prompt_file.exists():
            try:
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    prompt = f.read()
                print(f"ğŸ“„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ: {prompt_file.name}")
                return prompt
            except Exception as e:
                print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({prompt_file.name}): {e}. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©.")
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (prompt_v2.txt ë‚´ìš© ê¸°ë°˜)
        return """ì´ ì´ë¯¸ì§€ëŠ” ì¼ë³¸ì–´ ì¡°ê±´ì²­êµ¬ì„œ(æ¡ä»¶è«‹æ±‚æ›¸) ë¬¸ì„œì…ë‹ˆë‹¤.
ìì—°ì–´ ê¸°ë°˜ ì¶”ë¡ ì„ í†µí•´ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ì¤‘ìš”: ì´ë¯¸ì§€ ì•ˆì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ êµ¬ì¡°í™”í•´ì•¼ í•˜ë©°,
ëª¨ë¸ì´ ì„ì˜ë¡œ í–‰ì„ ì‚­ì œÂ·ìƒëµÂ·í†µí•©Â·ì¶•ì•½í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.
í‘œì˜ ëª¨ë“  í–‰ì€ ë°˜ë“œì‹œ 1í–‰ë„ ë¹ ì§ì—†ì´ ê°œë³„ itemìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
OCRë¡œ ì¸ì‹ëœ í–‰ì€ ì–´ë–¤ ì´ìœ ë¡œë„ ì œê±°í•˜ê±°ë‚˜ ë¬¶ì–´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

ë˜í•œ ë‹¤ìŒ ê·œì¹™ì„ ê°•í•˜ê²Œ ì ìš©í•˜ì„¸ìš”:
í‘œì˜ í–‰ì€ ì´ë¯¸ì§€ ìƒì—ì„œ ë³´ì´ëŠ” ìˆœì„œëŒ€ë¡œ, í•œ í–‰ë‹¹ í•˜ë‚˜ì˜ item ìœ¼ë¡œ 1:1 ëŒ€ì‘í•´ì•¼ í•©ë‹ˆë‹¤.
ìœ ì‚¬í•œ ì œí’ˆí–‰ì´ë¼ë„ ì ˆëŒ€ í†µí•©í•˜ê±°ë‚˜ ëŒ€í‘œí–‰ë§Œ ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”.
ê´€ë¦¬ç•ªå·(å“ç›®No, è«‹æ±‚No ë“±)ê°€ ë™ì¼í•˜ë”ë¼ë„, ê° í–‰ì„ ë³„ë„ì˜ itemìœ¼ë¡œ ë°˜ë“œì‹œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
í…ìŠ¤íŠ¸ê°€ í¬ë¯¸í•˜ê±°ë‚˜ ì„ ì— ê°€ê¹Œì›Œë„ ë°˜ë“œì‹œ ì¡´ì¬í•˜ëŠ” í–‰ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì¶”ì¶œí•˜ì„¸ìš”.
í–‰ ë‹¨ìœ„ ìŠ¤ìº”(line-by-line scan)ì„ ìˆ˜í–‰í•˜ê³ , ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  í–‰ì„ ëˆ„ë½ ì—†ì´ items ë°°ì—´ì— í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

ğŸ”· ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ

{
"items": [
{
"management_id": "ê´€ë¦¬ë²ˆí˜¸ (è«‹æ±‚No, å¥‘ç´„No, ç®¡ç†ç•ªå·, ä¼ç¥¨ç•ªå· ë“±)",
"product_name": "ìƒí’ˆëª… (ë°”ì½”ë“œ ì œê±° í›„)",
"quantity": "ì§ì ‘ ìˆ˜ëŸ‰ì´ ìˆì„ ë•Œë§Œ ìˆ«ì, ì¼€ì´ìŠ¤/ë°”ë¼ë§Œ ìˆì„ ê²½ìš° null",
"case_count": "ì¼€ì´ìŠ¤ ìˆ˜",
"bara_count": "ë°”ë¼ ìˆ˜",
"units_per_case": "ì¼€ì´ìŠ¤ ë‚´ ì…ìˆ˜",
"amount": "ê¸ˆì•¡",
"customer": "í•´ë‹¹ í–‰ì˜ ê±°ë˜ì²˜ (ì—†ìœ¼ë©´ null)"
}
],
"page_role": "cover | detail"
}

ğŸ”· í…Œì´ë¸” ì¸ì‹ ê·œì¹™
í‘œì˜ ëª¨ë“  í–‰(è¡Œ)ì€ ë°˜ë“œì‹œ itemìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
ê°™ì€ management_idê°€ ì—¬ëŸ¬ í–‰ì— ë°˜ë³µë˜ì–´ë„ ê° í–‰ì€ ë…ë¦½ itemì…ë‹ˆë‹¤.
ì ˆëŒ€ ìƒëµ, ì¶•ì•½, í†µí•©, ìš”ì•½, ëŒ€í‘œí–‰ ì„ íƒ ë“±ì„ í•˜ì§€ ë§ˆì„¸ìš”.
ì´ë¯¸ì§€ì— ìˆëŠ” í–‰ ìˆ˜ì™€ items ë°°ì—´ì˜ í–‰ ìˆ˜ëŠ” ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
ëª¨ë¸ì´ ì¶”ë¡ ìœ¼ë¡œ ë³´ì •í•˜ê±°ë‚˜ ì‚­ì œí•˜ì§€ ì•Šê³ , ì´ë¯¸ì§€ ì‹œê° ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.

ì»¬ëŸ¼ ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì¶œ:
ç®¡ç†ç•ªå· ê³„ì—´ â†’ management_id
å–å¼•å…ˆ ê³„ì—´ â†’ customer
å•†å“å ê³„ì—´ â†’ product_name
ã‚±ãƒ¼ã‚¹å†…å…¥æ•° â†’ units_per_case
æ•°é‡ â†’ case_count / bara_count
é‡‘é¡ ê³„ì—´ â†’ amount

ë°”ì½”ë“œ(13ìë¦¬ ìˆ«ì)ê°€ ìˆì„ ê²½ìš° product_nameì—ì„œ ì œê±°í•˜ê³  ìˆœìˆ˜ ìƒí’ˆëª…ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

ğŸ”· ì¶”ê°€ ê·œì¹™ (í–‰ ëˆ„ë½ ë°©ì§€ ê°•í™”)
ì´ë¯¸ì§€ì˜ í‘œ êµ¬ì¡°ë¥¼ ì¬í•´ì„í•˜ê±°ë‚˜ ëª¨ë¸ì´ íŒë‹¨í•˜ì—¬ í–‰ì„ ì œê±°í•˜ëŠ” í–‰ë™ì„ ê¸ˆì§€í•©ë‹ˆë‹¤.
í‘œì˜ ì–‡ì€ ê¸€ì, í¬ë¯¸í•œ ê¸€ì, ì„¸ë¡œì„ ì— ê°€ê¹Œìš´ ê¸€ìë„ ëª¨ë‘ í…ìŠ¤íŠ¸ë¡œ ì¸ì‹í•˜ì—¬ itemìœ¼ë¡œ ë°˜ë“œì‹œ í¬í•¨í•©ë‹ˆë‹¤.
itemsëŠ” ì´ë¯¸ì§€ì˜ ê° í–‰(line)ê³¼ ì •í™•íˆ 1:1ë¡œ ëŒ€ì‘ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ëª¨ë¸ì´ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨í•˜ì—¬ êµ¬ì„± ë³€ê²½ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ì˜¤ì§ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” í…ìŠ¤íŠ¸ì™€ ìœ„ì¹˜ë§Œì„ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    def _image_to_base64(self, image: Image.Image) -> str:
        """
        PIL Imageë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜
        
        Args:
            image: PIL Image ê°ì²´
            
        Returns:
            base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´
        """
        from io import BytesIO
        buffered = BytesIO()
        # JPEG í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (RGB ëª¨ë“œ í•„ìš”)
        if image.mode != 'RGB':
            image = image.convert('RGB')
        image.save(buffered, format="JPEG", quality=95)
        img_str = base64.b64encode(buffered.getvalue()).decode()
        return img_str
    
    def parse_image(self, image: Image.Image, max_size: int = 1000, timeout: int = 120) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ë¥¼ OpenAI Visionìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ JSON ë°˜í™˜
        
        Args:
            image: PIL Image ê°ì²´
            max_size: OpenAI APIì— ì „ë‹¬í•  ìµœëŒ€ ì´ë¯¸ì§€ í¬ê¸° (í”½ì…€, ê¸°ë³¸ê°’: 1000)
                      ì†ë„ ê°œì„ ì„ ìœ„í•´ í° ì´ë¯¸ì§€ëŠ” ë¦¬ì‚¬ì´ì¦ˆë¨
            timeout: API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì´ˆ, ê¸°ë³¸ê°’: 120ì´ˆ = 2ë¶„)
            
        Returns:
            íŒŒì‹± ê²°ê³¼ JSON ë”•ì…”ë„ˆë¦¬
        """
        # ì›ë³¸ ì´ë¯¸ì§€ ì •ë³´
        original_width, original_height = image.size
        
        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (OpenAI API ì†ë„ ê°œì„ ì„ ìœ„í•´)
        api_image = image
        if original_width > max_size or original_height > max_size:
            # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
            ratio = min(max_size / original_width, max_size / original_height)
            new_width = int(original_width * ratio)
            new_height = int(original_height * ratio)
            api_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            print(f"  ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ: {original_width}x{original_height}px â†’ {new_width}x{new_height}px", end="", flush=True)
        else:
            print(f"  ì´ë¯¸ì§€ í¬ê¸°: {original_width}x{original_height}px", end="", flush=True)
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
        image_base64 = self._image_to_base64(api_image)
        
        # OpenAI API í˜¸ì¶œ: ì¬ì‹œë„ ë¡œì§ í¬í•¨
        max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        retry_delay = 2  # ì¬ì‹œë„ ì „ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": self.get_parsing_prompt()
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{image_base64}"
                                    }
                                }
                            ]
                        }
                    ],
                    timeout=timeout
                )
                
                # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                result_text = response.choices[0].message.content
                
                if not result_text:
                    raise Exception("OpenAI API ì‘ë‹µì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # JSON ì¶”ì¶œ ì‹œë„
                try:
                    # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
                    json_match = re.search(r'\{.*\}', result_text, re.DOTALL)  # JSON ê°ì²´ ì¶”ì¶œ
                    if json_match:
                        result_json = json.loads(json_match.group())  # JSON íŒŒì‹±
                        return result_json
                    else:
                        # JSONì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
                        return {"text": result_text}
                except json.JSONDecodeError:
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
                    return {"text": result_text}
                
            except Exception as e:
                error_msg = str(e)
                if attempt < max_retries - 1:
                    print(f"  âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}), {retry_delay}ì´ˆ í›„ ì¬ì‹œë„...", end="", flush=True)
                    time.sleep(retry_delay)
                    retry_delay *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    continue
                else:
                    # ë§ˆì§€ë§‰ ì‹œë„ë„ ì‹¤íŒ¨í•˜ë©´ ì˜ˆì™¸ ë°œìƒ
                    raise Exception(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ ({max_retries}íšŒ ì‹œë„): {error_msg}")


class OpenAITextParser:
    """OpenAI Chat APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ íŒŒì‹±"""
    
    def __init__(self, api_key: Optional[str] = None, model_name: str = "gpt-4o-mini", prompt_version: str = "v2"):
        """
        Args:
            api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
            model_name: ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: "gpt-4o-mini")
            prompt_version: í”„ë¡¬í”„íŠ¸ ë²„ì „ (ê¸°ë³¸ê°’: "v2", prompts/prompt_v2.txt íŒŒì¼ ì‚¬ìš©)
        """
        if api_key is None:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•˜ì„¸ìš”.")
        
        self.client = OpenAI(api_key=api_key)
        self.model_name = model_name
        self.prompt_version = prompt_version
    
    def get_parsing_prompt(self) -> str:
        """
        í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸
        
        Returns:
            íŒŒì‹± í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ ìƒì„±
        prompt_file = Path(__file__).parent.parent / "prompts" / f"prompt_{self.prompt_version}.txt"
        
        # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì½ê¸°
        if prompt_file.exists():
            try:
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    prompt = f.read()
                return prompt
            except Exception as e:
                print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({prompt_file.name}): {e}")
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (prompt_v2.txt ë‚´ìš© ê¸°ë°˜, í…ìŠ¤íŠ¸ìš©ìœ¼ë¡œ ìˆ˜ì •)
        return """ë‹¤ìŒì€ ì¼ë³¸ì–´ ì¡°ê±´ì²­êµ¬ì„œ(æ¡ä»¶è«‹æ±‚æ›¸) ë¬¸ì„œì˜ OCR ì¶”ì¶œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

{
  "items": [
    {
      "management_id": "ê´€ë¦¬ë²ˆí˜¸ - ê° í–‰/í•­ëª©ë§ˆë‹¤ ë‹¤ë¥¸ ê´€ë¦¬ë²ˆí˜¸ê°€ ìˆì„ ìˆ˜ ìˆìŒ (è«‹æ±‚No, å¥‘ç´„No, ç®¡ç†ç•ªå·, ä¼ç¥¨ç•ªå· ë“±). ê°™ì€ management_idê°€ ì—¬ëŸ¬ í–‰ì— ìˆìœ¼ë©´ ê° í–‰ì„ ë³„ë„ì˜ itemìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•¨",
      "product_name": "ìƒí’ˆëª… (å•†å“å, å“å, ä»¶å ë“±) - ì œí’ˆë²ˆí˜¸(13ìë¦¬ ìˆ«ì ë°”ì½”ë“œ, ì˜ˆ: 8801043157506)ê°€ ì•ì— ìˆìœ¼ë©´ ì œì™¸í•˜ê³  ìˆœìˆ˜ ìƒí’ˆëª…ë§Œ ì¶”ì¶œ",
      "quantity": "ìˆ˜ëŸ‰ (ç›´æ¥çš„ãªæ•°é‡ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã€æ•°å€¤ã€‚ã‚±ãƒ¼ã‚¹/ãƒãƒ©ã§è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ null)",
      "case_count": "ã‚±ãƒ¼ã‚¹æ•° (ã‚±ãƒ¼ã‚¹å˜ä½ã®æ•°é‡ã€ä¾‹: 58ã‚±ãƒ¼ã‚¹ â†’ 58, ãªã„å ´åˆã¯ null)",
      "bara_count": "ãƒãƒ©æ•° (ãƒãƒ©å˜ä½ã®æ•°é‡ã€ä¾‹: 6ãƒãƒ© â†’ 6, ãªã„å ´åˆã¯ null)",
      "units_per_case": "ã‚±ãƒ¼ã‚¹å†…å…¥æ•° (ì¼€ì´ìŠ¤ë‹¹ ê°œìˆ˜) - ì˜ˆ: 12x1ì´ë©´ 12, 30x1ì´ë©´ 30, 12x2ì´ë©´ 24 (ì—†ìœ¼ë©´ null)",
      "amount": "ê¸ˆì•¡ (é‡‘é¡, ç¨è¾¼é‡‘é¡ ë“±)",
      "customer": "í•­ëª©ë³„ ê±°ë˜ì²˜(ìµœì¢… íŒë§¤ì²˜) - í•´ë‹¹ í•­ëª©ì˜ ê±°ë˜ì²˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ (ì—†ìœ¼ë©´ null)"
    }
  ],
  "page_role": "í˜ì´ì§€ ì—­í•  íŒë‹¨: cover(í‘œì§€), detail(ìƒì„¸ë‚´ì—­)"
}

**ì¤‘ìš”: items ë°°ì—´ì—ëŠ” í‘œì˜ ëª¨ë“  í–‰ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ê°™ì€ management_idë¥¼ ê°€ì§„ í–‰ì´ ì—¬ëŸ¬ ê°œ ìˆì–´ë„ ê°ê° ë³„ë„ì˜ itemìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ëˆ„ë½ ì—†ì´ ëª¨ë“  í–‰ì„ ì¶”ì¶œí•˜ì„¸ìš”.**

í‘œ êµ¬ì¡° ì¸ì‹ ë° ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì¶œ:
- ë¬¸ì„œì— í‘œ(í…Œì´ë¸”)ê°€ ìˆëŠ” ê²½ìš°, í‘œì˜ ì»¬ëŸ¼ í—¤ë”ë¥¼ ë¨¼ì € ì¸ì‹í•©ë‹ˆë‹¤.
- í‘œì˜ ê° í–‰(è¡Œ)ì€ í•˜ë‚˜ì˜ itemì— í•´ë‹¹í•©ë‹ˆë‹¤.
- **ì¤‘ìš”: ê°™ì€ management_idë¥¼ ê°€ì§„ ëª¨ë“  í–‰ì„ ë°˜ë“œì‹œ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ìµœìƒë‹¨ í•œ ê°œë§Œ ì¶”ì¶œí•˜ì§€ ë§ê³ , ê°™ì€ management_idë¥¼ ê°€ì§„ ëª¨ë“  í–‰ì„ items ë°°ì—´ì— í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.**
- í‘œì˜ ì»¬ëŸ¼ ìœ„ì¹˜ì— ë”°ë¼ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤:
  * "è«‹æ±‚No", "å¥‘ç´„No", "ç®¡ç†ç•ªå·", "ä¼ç¥¨ç•ªå·" ë“±ì˜ ì»¬ëŸ¼ â†’ management_id (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "å–å¼•å…ˆ", "å¾—æ„å…ˆ", "è«‹æ±‚å…ˆ", "ç´å“å…ˆ", "å®¢å…ˆ" ë“±ì˜ ì»¬ëŸ¼ â†’ customer (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’, ìœ„ì¹˜ìƒ ë§ìœ¼ë©´ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œ)
  * "å•†å“å", "å“å", "ä»¶å" ë“±ì˜ ì»¬ëŸ¼ â†’ product_name (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "ã‚±ãƒ¼ã‚¹å†…å…¥æ•°" ì»¬ëŸ¼ â†’ units_per_case (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "æ•°é‡" ì»¬ëŸ¼ì˜ "ã‚±ãƒ¼ã‚¹" í•˜ìœ„ ê°’ â†’ case_count (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "æ•°é‡" ì»¬ëŸ¼ì˜ "ãƒãƒ©" í•˜ìœ„ ê°’ â†’ bara_count (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "è«‹æ±‚é‡‘é¡", "é‡‘é¡", "ç¨è¾¼é‡‘é¡" ë“±ì˜ ì»¬ëŸ¼ â†’ amount (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
- í‘œì—ì„œ "å–å¼•å…ˆ" ì»¬ëŸ¼ì— ìˆëŠ” ê°’ì€ ê·¸ ìœ„ì¹˜ìƒ ê±°ë˜ì²˜ëª…ì´ë¯€ë¡œ, ì˜ë¯¸ íŒë‹¨ë³´ë‹¤ ìœ„ì¹˜ ì •ë³´ë¥¼ ìš°ì„ í•˜ì—¬ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ê°™ì€ management_idë¥¼ ê°€ì§„ ì—¬ëŸ¬ í–‰ì´ ê°™ì€ customer ê°’ì„ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ê·¸ë£¹ ë‹¨ìœ„ë¡œ í‘œì‹œë˜ëŠ” ê²½ìš°).
- **ê°™ì€ management_idê°€ ì—¬ëŸ¬ í–‰ì— ë°˜ë³µë˜ëŠ” ê²½ìš°, ê° í–‰ì„ ë³„ë„ì˜ itemìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ëˆ„ë½ ì—†ì´ ëª¨ë“  í–‰ì„ ì¶”ì¶œí•˜ì„¸ìš”.**

ì¶”ì¶œ ê°€ì´ë“œ:
- customerëŠ” ìµœì¢… íŒë§¤ì²˜(ìµœì¢… ì†Œë§¤ ì²´ì¸)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‹ë³„í•©ë‹ˆë‹¤. ì˜ˆ: ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãƒãƒ¼ãƒˆ, ã‚»ãƒ–ãƒ³ã‚¤ãƒ¬ãƒ–ãƒ³, ãƒ­ãƒ”ã‚¢, ã‚¹ãƒ¼ãƒ‘ãƒ¼ ë“±
- customerëŠ” íŒ¨ë°€ë¦¬ë§ˆíŠ¸, ì„¸ë¸ì¼ë ˆë¸, ìŠˆí¼ ë“± ìµœì¢… íŒë§¤ì²˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ë©°, ë„ë§¤ìƒ(å¸), ë¬¼ë¥˜ì„¼í„°, ë°°ì†¡ì²˜ëŠ” customerë¡œ ë¶„ë¥˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì…ì¶œí•˜ì„¼í„°(å…¥å‡ºè·ã‚»ãƒ³ã‚¿ãƒ¼), ë¬¼ë¥˜ì„¼í„°(ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼), ë°°ì†¡ì²˜(é…é€å…ˆ) ë“±ì˜ ì •ë³´ëŠ” ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- management_idëŠ” ê° í•­ëª©(items)ë§ˆë‹¤ ì¶”ì¶œí•©ë‹ˆë‹¤. í•œ í˜ì´ì§€ì— ì—¬ëŸ¬ ê´€ë¦¬ë²ˆí˜¸ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- í‘œë‚˜ í…Œì´ë¸”ì˜ ê° í–‰ë§ˆë‹¤ management_id(è«‹æ±‚No, å¥‘ç´„No ë“±)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
- **ì¤‘ìš”: ê°™ì€ management_idë¥¼ ê°€ì§„ ì—¬ëŸ¬ í–‰ì´ ìˆìœ¼ë©´, ê° í–‰ì„ ë³„ë„ì˜ itemìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. í•œ ê°œë§Œ ì¶”ì¶œí•˜ì§€ ë§ê³  ëª¨ë“  í–‰ì„ ì¶”ì¶œí•˜ì„¸ìš”.**
- ê° í•­ëª©(items)ë§ˆë‹¤ customerê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•­ëª©ë³„ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
- **í‘œì˜ ëª¨ë“  í–‰ì„ ë¹ ì§ì—†ì´ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ê°™ì€ management_idê°€ ë°˜ë³µë˜ì–´ë„ ê° í–‰ì€ ë³„ë„ì˜ itemì…ë‹ˆë‹¤.**
- quantityëŠ” ì§ì ‘ì ì¸ ìˆ˜ëŸ‰ì´ ëª…ì‹œë˜ì–´ ìˆì„ ë•Œë§Œ ìˆ«ìë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. ì˜ˆ: "100å€‹" â†’ 100, "50æœ¬" â†’ 50. ì¼€ì´ìŠ¤/ë°”ë¼ë¡œë§Œ í‘œì‹œëœ ê²½ìš°ëŠ” nullì…ë‹ˆë‹¤.
- case_countëŠ” ì¼€ì´ìŠ¤ ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆ: "58ã‚±ãƒ¼ã‚¹ 6ãƒãƒ©" â†’ case_count: 58, "67ã‚±ãƒ¼ã‚¹ 0ãƒãƒ©" â†’ case_count: 67. ì¼€ì´ìŠ¤ ì •ë³´ê°€ ì—†ìœ¼ë©´ nullì…ë‹ˆë‹¤.
- bara_countëŠ” ë°”ë¼ ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆ: "58ã‚±ãƒ¼ã‚¹ 6ãƒãƒ©" â†’ bara_count: 6, "67ã‚±ãƒ¼ã‚¹ 0ãƒãƒ©" â†’ bara_count: 0 ë˜ëŠ” null. ë°”ë¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ nullì…ë‹ˆë‹¤.
- units_per_case(ã‚±ãƒ¼ã‚¹å†…å…¥æ•°)ëŠ” ì¼€ì´ìŠ¤ë‹¹ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. "12x1"ì´ë©´ 12, "30x1"ì´ë©´ 30, "12x2"ì´ë©´ 24ì…ë‹ˆë‹¤. í…Œì´ë¸”ì˜ "ã‚±ãƒ¼ã‚¹å†…å…¥æ•°" ì»¬ëŸ¼ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.
- product_nameì—ì„œ ì œí’ˆë²ˆí˜¸(13ìë¦¬ ìˆ«ì ë°”ì½”ë“œ, ì˜ˆ: 8801043157506)ê°€ ì•ì— ìˆìœ¼ë©´ ì œê±°í•˜ê³  ìˆœìˆ˜ ìƒí’ˆëª…ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. ì˜ˆ: "8801043157506 ãƒã‚¦ã‚·ãƒ³ è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ 3é£Ÿ" â†’ "ãƒã‚¦ã‚·ãƒ³ è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ 3é£Ÿ", "8801043030694 è¾²å¿ƒ NEWè¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ã‚«ãƒƒãƒ— 68g" â†’ "è¾²å¿ƒ NEWè¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ã‚«ãƒƒãƒ— 68g"
- í‘œí˜„ì´ ë‹¤ì–‘í•´ë„ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ê°™ì€ í•„ë“œë¡œ ì¸ì‹í•©ë‹ˆë‹¤ (ì˜ˆ: è«‹æ±‚Noì™€ å¥‘ç´„NoëŠ” ëª¨ë‘ management_id)
- ì •ë³´ê°€ ì—†ìœ¼ë©´ nullì„ ì‚¬ìš©í•©ë‹ˆë‹¤
- JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³  ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ì¶”ê°€ ì¶”ì¶œ ê·œì¹™:
- í‘œì—ì„œ "å–å¼•å…ˆ" ì»¬ëŸ¼ ìœ„ì¹˜ì— ìˆëŠ” ê°’ì€ ìœ„ì¹˜ìƒ ê±°ë˜ì²˜ëª…ì´ë¯€ë¡œ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. ì˜ë¯¸ íŒë‹¨ë³´ë‹¤ ìœ„ì¹˜ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•©ë‹ˆë‹¤.
- customerëŠ” ìµœì¢… íŒë§¤ì²˜(ìµœì¢… ì†Œë§¤ ì²´ì¸)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ë©°, í‘œì˜ "å–å¼•å…ˆ" ì»¬ëŸ¼ì— ëª…ì‹œëœ ê°’ì€ ê·¸ ìœ„ì¹˜ìƒ ê±°ë˜ì²˜ëª…ì´ë¯€ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ë„ë§¤ìƒ(å¸), ë¬¼ë¥˜ì„¼í„°, ë°°ì†¡ì½”ë“œê°€ ìˆëŠ” ì‚¬ì—…ì†Œ, ì…ì¶œí•˜ì„¼í„°(å…¥å‡ºè·ã‚»ãƒ³ã‚¿ãƒ¼), ë¬¼ë¥˜ì„¼í„°(ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼)ëŠ” customerë¡œ ë¶„ë¥˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- í‘œì˜ "å–å¼•å…ˆ" ì»¬ëŸ¼ì— ìˆëŠ” ê°’ì€ ìœ„ì¹˜ìƒ ê±°ë˜ì²˜ëª…ì´ë¯€ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    def parse_text(self, text: str, timeout: int = 120, reference_json: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ë¥¼ OpenAI Chat APIë¡œ íŒŒì‹±í•˜ì—¬ JSON ë°˜í™˜
        
        Args:
            text: Upstage ë“±ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸
            timeout: API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì´ˆ, ê¸°ë³¸ê°’: 120ì´ˆ = 2ë¶„)
            reference_json: ê¸°ì¤€ í˜ì´ì§€ì˜ JSON ì •ë³´ (ë‹¤ë¥¸ í˜ì´ì§€ ì¶”ì¶œ ì‹œ ì°¸ì¡°ìš©, ê¸°ë³¸ê°’: None)
            
        Returns:
            íŒŒì‹± ê²°ê³¼ JSON ë”•ì…”ë„ˆë¦¬
        """
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self.get_parsing_prompt()
        
        # ê¸°ì¤€ JSONì´ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        reference_section = ""
        if reference_json:
            reference_json_str = json.dumps(reference_json, ensure_ascii=False, indent=2)
            reference_section = f"\n\n**ê¸°ì¤€ í˜ì´ì§€ ì •ë³´ (ì°¸ì¡°ìš©)**:\në‹¤ìŒì€ ê°™ì€ ë¬¸ì„œì˜ ë‹¤ë¥¸ í˜ì´ì§€(ê¸°ì¤€ í˜ì´ì§€)ì—ì„œ ì¶”ì¶œí•œ JSON ì •ë³´ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë™ì¼í•œ í˜•ì‹ê³¼ êµ¬ì¡°ë¡œ ì¶”ì¶œí•˜ë˜, í˜„ì¬ í˜ì´ì§€ì˜ ì‹¤ì œ ë‚´ìš©ì— ë§ê²Œ ì¶”ì¶œí•˜ì„¸ìš”:\n\n```json\n{reference_json_str}\n```\n\nìœ„ ê¸°ì¤€ í˜ì´ì§€ì˜ êµ¬ì¡°ì™€ í•„ë“œ í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬, í˜„ì¬ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”."
        
        full_prompt = f"{prompt}{reference_section}\n\në‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:\n\n{text}\n\nìœ„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”."
        
        # OpenAI API í˜¸ì¶œ: ì¬ì‹œë„ ë¡œì§ í¬í•¨
        max_retries = 3
        retry_delay = 2
        
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "user",
                            "content": full_prompt
                        }
                    ],
                    timeout=timeout
                )
                
                # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                result_text = response.choices[0].message.content
                
                if not result_text:
                    raise Exception("OpenAI API ì‘ë‹µì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # JSON ì¶”ì¶œ ì‹œë„
                try:
                    # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
                    json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
                    if json_match:
                        result_json = json.loads(json_match.group())
                        return result_json
                    else:
                        # JSONì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
                        return {"text": result_text, "error": "JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
                except json.JSONDecodeError as e:
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
                    return {"text": result_text, "error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}"}
                
            except Exception as e:
                error_msg = str(e)
                if attempt < max_retries - 1:
                    print(f"  âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}), {retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                else:
                    raise Exception(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ ({max_retries}íšŒ ì‹œë„): {error_msg}")


def extract_json_from_text(text: str, api_key: Optional[str] = None, model_name: str = "gpt-4o-mini", prompt_version: str = "v2", reference_json: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ë¥¼ OpenAI APIë¡œ ë¶„ì„í•˜ì—¬ JSON ê²°ê³¼ ë°˜í™˜ (í¸ì˜ í•¨ìˆ˜)
    
    Args:
        text: Upstage ë“±ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸
        api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        model_name: OpenAI ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: "gpt-4o-mini")
        prompt_version: í”„ë¡¬í”„íŠ¸ ë²„ì „ (ê¸°ë³¸ê°’: "v2")
        reference_json: ê¸°ì¤€ í˜ì´ì§€ì˜ JSON ì •ë³´ (ë‹¤ë¥¸ í˜ì´ì§€ ì¶”ì¶œ ì‹œ ì°¸ì¡°ìš©, ê¸°ë³¸ê°’: None)
        
    Returns:
        íŒŒì‹± ê²°ê³¼ JSON ë”•ì…”ë„ˆë¦¬
    """
    parser = OpenAITextParser(api_key=api_key, model_name=model_name, prompt_version=prompt_version)
    return parser.parse_text(text, reference_json=reference_json)


def extract_pages_with_openai(
    pdf_path: str,
    openai_api_key: Optional[str] = None,
    openai_model: str = "gpt-5-mini-2025-08-07",
    dpi: int = 300,
    use_openai_cache: bool = False,  # ìºì‹œ ë¹„í™œì„±í™” (DB ì‚¬ìš©)
    openai_cache_path: Optional[str] = None,
    save_images: bool = False,  # ë¡œì»¬ ì €ì¥ ë¹„í™œì„±í™” (ê¸°ë³¸ê°’: False)
    image_output_dir: Optional[str] = None,
    use_history: bool = False,  # íˆìŠ¤í† ë¦¬ ë¹„í™œì„±í™”
    history_dir: Optional[str] = None
) -> tuple[List[Dict[str, Any]], List[str], Optional[List[Image.Image]]]:
    """
    PDF íŒŒì¼ì„ OpenAIë¡œ ë¶„ì„í•˜ì—¬ í˜ì´ì§€ë³„ JSON ê²°ê³¼ ë°˜í™˜
    
    DBë¥¼ ìš°ì„  ì‚¬ìš©í•˜ë©°, DBì— ë°ì´í„°ê°€ ì—†ì„ ë•Œë§Œ OpenAI APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    ìºì‹œ íŒŒì¼ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        openai_api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
        openai_model: OpenAI ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: "gpt-5-mini-2025-08-07")
        dpi: PDF ë³€í™˜ í•´ìƒë„ (ê¸°ë³¸ê°’: 300)
        use_openai_cache: OpenAI ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, ì‚¬ìš© ì•ˆ í•¨)
        openai_cache_path: OpenAI ìºì‹œ íŒŒì¼ ê²½ë¡œ (ì‚¬ìš© ì•ˆ í•¨)
        save_images: ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: False, ì‚¬ìš© ì•ˆ í•¨)
        image_output_dir: ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ (ì‚¬ìš© ì•ˆ í•¨)
        use_history: íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, ì‚¬ìš© ì•ˆ í•¨)
        history_dir: íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ (ì‚¬ìš© ì•ˆ í•¨)
        
    Returns:
        (í˜ì´ì§€ë³„ OpenAI íŒŒì‹± ê²°ê³¼ JSON ë¦¬ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸, PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
        ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œëŠ” í•­ìƒ None ë¦¬ìŠ¤íŠ¸ (ë¡œì»¬ ì €ì¥ ë¹„í™œì„±í™”)
        PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸ëŠ” ìƒˆë¡œ ë³€í™˜í•œ ê²½ìš°ì—ë§Œ ë°˜í™˜
    """
    pdf_name = Path(pdf_path).stem
    pdf_filename = f"{pdf_name}.pdf"
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™” (ë¡œì»¬ ì €ì¥ ë¹„í™œì„±í™”ë¡œ í•­ìƒ None ë¦¬ìŠ¤íŠ¸)
    image_paths = []
    pil_images = None  # PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸ (ìƒˆë¡œ ë³€í™˜í•œ ê²½ìš°ì—ë§Œ)
    
    # 1. DBì—ì„œ ë¨¼ì € í™•ì¸
    page_jsons = None
    try:
        from database.registry import get_db
        db_manager = get_db()
        page_jsons = db_manager.get_page_results(
            pdf_filename=pdf_filename,
            session_id=None,
            is_latest=True
        )
        if page_jsons and len(page_jsons) > 0:
            print(f"ğŸ’¾ DBì—ì„œ ê¸°ì¡´ íŒŒì‹± ê²°ê³¼ ë¡œë“œ: {len(page_jsons)}ê°œ í˜ì´ì§€")
            # DBì—ì„œ ë¡œë“œí•œ ê²½ìš° ì´ë¯¸ì§€ëŠ” None (ì´ë¯¸ DBì— ì €ì¥ë˜ì–´ ìˆìŒ)
            image_paths = [None] * len(page_jsons)
            return page_jsons, image_paths, None
    except Exception as db_error:
        print(f"âš ï¸ DB í™•ì¸ ì‹¤íŒ¨: {db_error}. ìƒˆë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.")
    
    # 2. DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ OpenAI API í˜¸ì¶œ
    # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    pdf_processor = PDFProcessor(dpi=dpi)  # PDF ì²˜ë¦¬ê¸° ìƒì„±
    images = pdf_processor.convert_pdf_to_images(pdf_path)  # PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
    pil_images = images  # PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸ ì €ì¥ (DB ì €ì¥ìš©)
    print(f"PDF ë³€í™˜ ì™„ë£Œ: {len(images)}ê°œ í˜ì´ì§€")
    
    # ë¡œì»¬ ì €ì¥ ë¹„í™œì„±í™” (DBì—ë§Œ ì €ì¥)
    image_paths = [None] * len(images)  # í•­ìƒ None ë¦¬ìŠ¤íŠ¸
    
    # OpenAI Visionìœ¼ë¡œ ê° í˜ì´ì§€ íŒŒì‹±
    openai_parser = OpenAIVisionParser(api_key=openai_api_key, model_name=openai_model, prompt_version="v2")  # OpenAI íŒŒì„œ ìƒì„±
    page_jsons = []
    
    # ê° í˜ì´ì§€ íŒŒì‹± (ì²˜ìŒë¶€í„° ì‹œì‘)
    start_idx = 0
    total_parse_time = 0.0
    
    # í˜ì´ì§€ ìˆ˜ê°€ ì¶©ë¶„íˆ ë§ì„ ë•Œë§Œ ë©€í‹°ìŠ¤ë ˆë”© ì‚¬ìš© (ì˜¤ë²„í—¤ë“œ ê³ ë ¤)
    use_parallel = (len(images) - start_idx) > 1
    
    if use_parallel:
        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ë³‘ë ¬ íŒŒì‹±
        completed_count = 0  # ì™„ë£Œëœ í˜ì´ì§€ ìˆ˜ ì¶”ì 
        results_lock = Lock()  # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì‹œ ë™ê¸°í™”ìš©
        
        def parse_single_page(idx: int) -> tuple[int, Dict[str, Any], float, Optional[str]]:
            """ë‹¨ì¼ í˜ì´ì§€ íŒŒì‹± í•¨ìˆ˜ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰) - ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë³„ë„ì˜ íŒŒì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
            parse_start_time = time.time()
            try:
                # ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë³„ë„ì˜ íŒŒì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (thread-safe)
                thread_parser = OpenAIVisionParser(api_key=openai_api_key, model_name=openai_model)
                page_json = thread_parser.parse_image(images[idx])  # ê° í˜ì´ì§€ íŒŒì‹±
                parse_end_time = time.time()
                parse_duration = parse_end_time - parse_start_time
                return (idx, page_json, parse_duration, None)
            except Exception as e:
                parse_end_time = time.time()
                parse_duration = parse_end_time - parse_start_time
                error_result = {"text": f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}", "error": True}
                return (idx, error_result, parse_duration, str(e))
        
        # ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 5ê°œ ìŠ¤ë ˆë“œ)
        max_workers = min(5, len(images) - start_idx)  # ìµœëŒ€ 5ê°œ ìŠ¤ë ˆë“œ ë˜ëŠ” ë‚¨ì€ í˜ì´ì§€ ìˆ˜ ì¤‘ ì‘ì€ ê°’
        print(f"ğŸš€ ë©€í‹°ìŠ¤ë ˆë”© íŒŒì‹± ì‹œì‘ (ìµœëŒ€ {max_workers}ê°œ ìŠ¤ë ˆë“œ)")
        
        # ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ (ì¸ë±ìŠ¤ ìˆœì„œ ë³´ì¥)
        parsed_results = {}
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ëª¨ë“  í˜ì´ì§€ì— ëŒ€í•´ Future ì œì¶œ
            future_to_idx = {
                executor.submit(parse_single_page, idx): idx 
                for idx in range(start_idx, len(images))
            }
            
            # ì™„ë£Œëœ ì‘ì—…ë¶€í„° ì²˜ë¦¬
            for future in as_completed(future_to_idx):
                idx, page_json, parse_duration, error = future.result()
                total_parse_time += parse_duration
                
                # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥ (ì¸ë±ìŠ¤ ìˆœì„œ ë³´ì¥)
                with results_lock:
                    parsed_results[idx] = page_json
                    completed_count += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if error:
                    print(f"í˜ì´ì§€ {idx+1}/{len(images)} íŒŒì‹± ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {parse_duration:.2f}ì´ˆ) - {error}")
                else:
                    print(f"í˜ì´ì§€ {idx+1}/{len(images)} íŒŒì‹± ì™„ë£Œ (ì†Œìš” ì‹œê°„: {parse_duration:.2f}ì´ˆ) [{completed_count}/{len(images) - start_idx}]")
        
        # ìµœì¢… ê²°ê³¼ë¥¼ ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ page_jsonsì— ë°˜ì˜
        for idx in range(start_idx, len(images)):
            if idx in parsed_results:
                if idx < len(page_jsons):
                    page_jsons[idx] = parsed_results[idx]  # ì—…ë°ì´íŠ¸
                else:
                    # ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ë§ì¶”ê¸° ìœ„í•´ Noneìœ¼ë¡œ ì±„ìš´ í›„ ì¶”ê°€
                    while len(page_jsons) < idx:
                        page_jsons.append(None)
                    page_jsons.append(parsed_results[idx])  # ì¶”ê°€
    
    else:
        # ë‹¨ì¼ í˜ì´ì§€ì¸ ê²½ìš° ìˆœì°¨ ì²˜ë¦¬
        for idx in range(start_idx, len(images)):
            parse_start_time = time.time()  # íŒŒì‹± ì‹œê°„ ì¸¡ì • ì‹œì‘
            try:
                print(f"í˜ì´ì§€ {idx+1}/{len(images)} OpenAI Vision íŒŒì‹± ì¤‘...", end="", flush=True)
                
                page_json = openai_parser.parse_image(images[idx])  # ê° í˜ì´ì§€ íŒŒì‹±
                parse_end_time = time.time()
                parse_duration = parse_end_time - parse_start_time
                total_parse_time += parse_duration
                
                # í˜ì´ì§€ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€/ì—…ë°ì´íŠ¸
                if idx < len(page_jsons):
                    page_jsons[idx] = page_json  # ì—…ë°ì´íŠ¸
                else:
                    page_jsons.append(page_json)  # ì¶”ê°€
                
                # íŒŒì‹± ì‹œê°„ ì¶œë ¥
                print(f" ì™„ë£Œ (ì†Œìš” ì‹œê°„: {parse_duration:.2f}ì´ˆ)")
                
            except Exception as e:
                parse_end_time = time.time()
                parse_duration = parse_end_time - parse_start_time
                total_parse_time += parse_duration
                print(f" ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {parse_duration:.2f}ì´ˆ) - {e}")
                # ì‹¤íŒ¨í•œ í˜ì´ì§€ëŠ” ë¹ˆ ê²°ê³¼ë¡œ ì¶”ê°€
                if idx >= len(page_jsons):
                    page_jsons.append({"text": f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}", "error": True})
                # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                continue
        
    # ì „ì²´ íŒŒì‹± ì‹œê°„ ìš”ì•½ ì¶œë ¥
    if start_idx < len(images):
        parsed_count = len(images) - start_idx
        avg_time = total_parse_time / parsed_count if parsed_count > 0 else 0
        print(f"\nğŸ“Š íŒŒì‹± í†µê³„:")
        print(f"  - ìƒˆë¡œ íŒŒì‹±í•œ í˜ì´ì§€: {parsed_count}ê°œ")
        print(f"  - ì´ ì†Œìš” ì‹œê°„: {total_parse_time:.2f}ì´ˆ")
        print(f"  - í‰ê·  í˜ì´ì§€ë‹¹ ì‹œê°„: {avg_time:.2f}ì´ˆ")
    
    # ë¡œì»¬ ì €ì¥ ë¹„í™œì„±í™”ë¡œ image_pathsëŠ” í•­ìƒ None ë¦¬ìŠ¤íŠ¸
    if not image_paths and page_jsons:
        image_paths = [None] * len(page_jsons)
    
    return page_jsons, image_paths, pil_images
