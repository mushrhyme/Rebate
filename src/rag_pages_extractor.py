"""
RAG ê¸°ë°˜ í˜ì´ì§€ ì¶”ì¶œ ëª¨ë“ˆ

OCR í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œ í›„ ë²¡í„° DBì—ì„œ ìœ ì‚¬í•œ ì˜ˆì œë¥¼ ê²€ìƒ‰í•˜ê³ ,
RAGë¥¼ ì‚¬ìš©í•˜ì—¬ JSONì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import os
from pathlib import Path
from typing import List, Dict, Any, Optional, Callable
from PIL import Image

from src.upstage_extractor import UpstageExtractor
from src.rag_extractor import extract_json_with_rag


def extract_pages_with_rag(
    pdf_path: str,
    openai_api_key: Optional[str] = None,
    openai_model: str = "gpt-4o-2024-08-06",
    dpi: int = 300,
    save_images: bool = False,
    image_output_dir: Optional[str] = None,
    question: str = "ì´ ì²­êµ¬ì„œì˜ ìƒí’ˆë³„ ë‚´ì—­ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•´ë¼",
    top_k: int = 1,
    similarity_threshold: float = 0.7,
    progress_callback: Optional[Callable[[int, int, str], None]] = None
) -> tuple[List[Dict[str, Any]], List[str], Optional[List[Image.Image]]]:
    """
    PDF íŒŒì¼ì„ RAG ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í˜ì´ì§€ë³„ JSON ê²°ê³¼ ë°˜í™˜
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        openai_api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        openai_model: OpenAI ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: "gpt-4o-2024-08-06")
        dpi: PDF ë³€í™˜ í•´ìƒë„ (ê¸°ë³¸ê°’: 300)
        save_images: ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        image_output_dir: ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ (ì‚¬ìš© ì•ˆ í•¨)
        question: ì§ˆë¬¸ í…ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: "ì´ ì²­êµ¬ì„œì˜ ìƒí’ˆë³„ ë‚´ì—­ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•´ë¼")
        top_k: ê²€ìƒ‰í•  ì˜ˆì œ ìˆ˜ (ê¸°ë³¸ê°’: 1)
        similarity_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.7)
        
    Returns:
        (í˜ì´ì§€ë³„ JSON ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸, PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
    """
    pdf_name = Path(pdf_path).stem
    pdf_filename = f"{pdf_name}.pdf"
    
    # 1. DBì—ì„œ ë¨¼ì € í™•ì¸
    page_jsons = None
    try:
        from database.registry import get_db
        db_manager = get_db()
        page_jsons = db_manager.get_page_results(
            pdf_filename=pdf_filename,
            session_id=None,
            is_latest=True
        )
        if page_jsons and len(page_jsons) > 0:
            print(f"ğŸ’¾ DBì—ì„œ ê¸°ì¡´ íŒŒì‹± ê²°ê³¼ ë¡œë“œ: {len(page_jsons)}ê°œ í˜ì´ì§€")
            image_paths = [None] * len(page_jsons)
            return page_jsons, image_paths, None
    except Exception as db_error:
        print(f"âš ï¸ DB í™•ì¸ ì‹¤íŒ¨: {db_error}. ìƒˆë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.")
    
    # 2. DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ RAG ê¸°ë°˜ íŒŒì‹±
    # ë””ë²„ê¹… í´ë” ì„¤ì • (ì‹¤ì œ ë¶„ì„ì„ ìˆ˜í–‰í•  ë•Œë§Œ ìƒì„±)
    # src/rag_pages_extractor.py -> src -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
    project_root = Path(__file__).parent.parent
    debug_base_dir = project_root / "debug"
    debug_dir = debug_base_dir / pdf_name
    if debug_dir.exists():
        import shutil
        shutil.rmtree(debug_dir)
    debug_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ” ë””ë²„ê¹… ì •ë³´ ì €ì¥ ìœ„ì¹˜: {debug_dir}")
    # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    if progress_callback:
        progress_callback(0, 0, "ğŸ”„ PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì¤‘...")
    
    from src.openai_extractor import PDFProcessor
    pdf_processor = PDFProcessor(dpi=dpi)
    images = pdf_processor.convert_pdf_to_images(pdf_path)
    pil_images = images
    print(f"PDF ë³€í™˜ ì™„ë£Œ: {len(images)}ê°œ í˜ì´ì§€")
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    image_paths = [None] * len(images)
    
    # Upstageë¡œ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
    upstage_extractor = UpstageExtractor()
    page_jsons = []
    
    # ë””ë²„ê¹…: ë¶„ì„ í†µê³„
    analysis_stats = {
        "total": len(images),
        "success": 0,
        "failed": 0,
        "empty_items": 0,
        "with_items": 0,
        "page_details": []
    }
    
    # ê° í˜ì´ì§€ ì²˜ë¦¬
    for idx, image in enumerate(images):
        page_num = idx + 1
        total_pages = len(images)
        page_detail = {"page_num": page_num, "status": "unknown", "items_count": 0, "error": None}
        
        try:
            if progress_callback:
                progress_callback(page_num, total_pages, f"ğŸ“„ í˜ì´ì§€ {page_num}/{total_pages} ì²˜ë¦¬ ì¤‘...")
            
            print(f"í˜ì´ì§€ {page_num}/{total_pages} RAG íŒŒì‹± ì¤‘...", end="", flush=True)
            
            # ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥ (Upstage API ì‚¬ìš©)
            import tempfile
            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_file:
                image.save(tmp_file.name, "PNG")
                tmp_path = tmp_file.name
            
            try:
                # Upstageë¡œ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if progress_callback:
                    progress_callback(page_num, total_pages, f"ğŸ” í˜ì´ì§€ {page_num}/{total_pages}: Upstage OCR ì‘ì—… ì¤‘...")
                
                ocr_text = upstage_extractor.extract_text(tmp_path)
                if not ocr_text or len(ocr_text.strip()) == 0:
                    raise Exception("OCR í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                
                # RAG ê¸°ë°˜ JSON ì¶”ì¶œ
                if progress_callback:
                    progress_callback(page_num, total_pages, f"ğŸ” í˜ì´ì§€ {page_num}/{total_pages}: RAG ê²€ìƒ‰ ì¤‘...")
                
                # RAG ì¶”ì¶œìš© progress_callback ë˜í¼
                def rag_progress_wrapper(msg: str):
                    if progress_callback:
                        progress_callback(page_num, total_pages, f"ğŸ¤– í˜ì´ì§€ {page_num}/{total_pages}: {msg}")
                
                page_json = extract_json_with_rag(
                    ocr_text=ocr_text,
                    question=question,
                    model_name=openai_model,
                    temperature=0.0,
                    top_k=top_k,
                    similarity_threshold=similarity_threshold,
                    progress_callback=rag_progress_wrapper if progress_callback else None,
                    debug_dir=str(debug_dir),
                    page_num=page_num
                )
                
                # items ê°œìˆ˜ í™•ì¸ (page_jsonì´ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸)
                if not isinstance(page_json, dict):
                    raise Exception(f"ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹: {type(page_json)}. ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
                
                items = page_json.get("items", [])
                items_count = len(items) if items else 0
                page_detail["items_count"] = items_count
                
                if items_count > 0:
                    analysis_stats["with_items"] += 1
                    page_detail["status"] = "success_with_items"
                else:
                    analysis_stats["empty_items"] += 1
                    page_detail["status"] = "success_empty"
                
                analysis_stats["success"] += 1
                page_jsons.append(page_json)
                
                if progress_callback:
                    progress_callback(page_num, total_pages, f"âœ… í˜ì´ì§€ {page_num}/{total_pages} ì™„ë£Œ ({items_count}ê°œ items)")
                
                print(f" ì™„ë£Œ ({items_count}ê°œ items)")
                
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                try:
                    os.unlink(tmp_path)
                except Exception:
                    pass
                    
        except Exception as e:
            error_msg = str(e)
            print(f" ì‹¤íŒ¨ - {error_msg}")
            if progress_callback:
                progress_callback(page_num, total_pages, f"âŒ í˜ì´ì§€ {page_num}/{total_pages} ì‹¤íŒ¨: {error_msg}")
            
            analysis_stats["failed"] += 1
            page_detail["status"] = "failed"
            page_detail["error"] = error_msg
            
            # ì‹¤íŒ¨í•œ í˜ì´ì§€ëŠ” ë¹ˆ ê²°ê³¼ë¡œ ì¶”ê°€
            page_jsons.append({
                "items": [],
                "page_role": "detail",
                "error": error_msg
            })
            continue
        finally:
            analysis_stats["page_details"].append(page_detail)
    
    # ë¶„ì„ í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š RAG ë¶„ì„ í†µê³„:")
    print(f"  - ì „ì²´ í˜ì´ì§€: {analysis_stats['total']}ê°œ")
    print(f"  - ë¶„ì„ ì„±ê³µ: {analysis_stats['success']}ê°œ (items ìˆìŒ: {analysis_stats['with_items']}ê°œ, items ì—†ìŒ: {analysis_stats['empty_items']}ê°œ)")
    print(f"  - ë¶„ì„ ì‹¤íŒ¨: {analysis_stats['failed']}ê°œ")
    print(f"\nğŸ“‹ í˜ì´ì§€ë³„ ìƒì„¸:")
    for detail in analysis_stats["page_details"]:
        status_icon = "âœ…" if detail["status"].startswith("success") else "âŒ"
        items_info = f", {detail['items_count']}ê°œ items" if detail["items_count"] > 0 else ""
        error_info = f", ì˜¤ë¥˜: {detail['error']}" if detail.get("error") else ""
        print(f"  {status_icon} í˜ì´ì§€ {detail['page_num']}: {detail['status']}{items_info}{error_info}")
    
    return page_jsons, image_paths, pil_images

