"""
RAG ê¸°ë°˜ í˜ì´ì§€ ì¶”ì¶œ ëª¨ë“ˆ

OCR í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œ í›„ ë²¡í„° DBì—ì„œ ìœ ì‚¬í•œ ì˜ˆì œë¥¼ ê²€ìƒ‰í•˜ê³ ,
RAGë¥¼ ì‚¬ìš©í•˜ì—¬ JSONì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import os
import time
import tempfile
from pathlib import Path
from typing import List, Dict, Any, Optional, Callable
from PIL import Image
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

from src.upstage_extractor import UpstageExtractor
from src.rag_extractor import extract_json_with_rag


def extract_pages_with_rag(
    pdf_path: str,
    openai_api_key: Optional[str] = None,
    openai_model: Optional[str] = None,
    dpi: Optional[int] = None,
    save_images: bool = False,
    image_output_dir: Optional[str] = None,
    question: Optional[str] = None,
    top_k: Optional[int] = None,
    similarity_threshold: Optional[float] = None,
    progress_callback: Optional[Callable[[int, int, str], None]] = None
) -> tuple[List[Dict[str, Any]], List[str], Optional[List[Image.Image]]]:
    """
    PDF íŒŒì¼ì„ RAG ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í˜ì´ì§€ë³„ JSON ê²°ê³¼ ë°˜í™˜
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        openai_api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        openai_model: OpenAI ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        dpi: PDF ë³€í™˜ í•´ìƒë„ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        save_images: ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        image_output_dir: ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ (ì‚¬ìš© ì•ˆ í•¨)
        question: ì§ˆë¬¸ í…ìŠ¤íŠ¸ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        top_k: ê²€ìƒ‰í•  ì˜ˆì œ ìˆ˜ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        similarity_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        
    Returns:
        (í˜ì´ì§€ë³„ JSON ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸, PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
    """
    # ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸° (íŒŒë¼ë¯¸í„°ê°€ Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
    from modules.utils.config import get_rag_config
    config = get_rag_config()
    
    openai_model = openai_model or config.openai_model
    dpi = dpi or config.dpi
    question = question or config.question
    top_k = top_k if top_k is not None else config.top_k
    similarity_threshold = similarity_threshold if similarity_threshold is not None else config.similarity_threshold
    rag_llm_workers = config.rag_llm_parallel_workers  # RAG+LLM ë³‘ë ¬ ì›Œì»¤ ìˆ˜
    ocr_delay = config.ocr_request_delay  # OCR ìš”ì²­ ê°„ ë”œë ˆì´
    
    pdf_name = Path(pdf_path).stem
    pdf_filename = f"{pdf_name}.pdf"
    
    # 1. DBì—ì„œ ë¨¼ì € í™•ì¸
    page_jsons = None
    try:
        from database.registry import get_db
        db_manager = get_db()
        page_jsons = db_manager.get_page_results(
            pdf_filename=pdf_filename,
            session_id=None,
            is_latest=True
        )
        if page_jsons and len(page_jsons) > 0:
            print(f"ğŸ’¾ DBì—ì„œ ê¸°ì¡´ íŒŒì‹± ê²°ê³¼ ë¡œë“œ: {len(page_jsons)}ê°œ í˜ì´ì§€")
            image_paths = [None] * len(page_jsons)
            return page_jsons, image_paths, None
    except Exception as db_error:
        print(f"âš ï¸ DB í™•ì¸ ì‹¤íŒ¨: {db_error}. ìƒˆë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.")
    
    # 2. DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ RAG ê¸°ë°˜ íŒŒì‹±
    # ë””ë²„ê¹… í´ë” ì„¤ì • (ì‹¤ì œ ë¶„ì„ì„ ìˆ˜í–‰í•  ë•Œë§Œ ìƒì„±)
    from modules.utils.config import get_project_root
    project_root = get_project_root()
    debug_base_dir = project_root / "debug"
    debug_dir = debug_base_dir / pdf_name
    if debug_dir.exists():
        import shutil
        shutil.rmtree(debug_dir)
    debug_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ” ë””ë²„ê¹… ì •ë³´ ì €ì¥ ìœ„ì¹˜: {debug_dir}")
    # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    if progress_callback:
        progress_callback(0, 0, "ğŸ”„ PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì¤‘...")
    
    from src.pdf_processor import PdfImageConverter
    pdf_processor = PdfImageConverter(dpi=dpi)
    images = pdf_processor.convert_pdf_to_images(pdf_path)
    pil_images = images
    print(f"PDF ë³€í™˜ ì™„ë£Œ: {len(images)}ê°œ í˜ì´ì§€")
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    image_paths = [None] * len(images)
    
    # ë””ë²„ê¹…: ë¶„ì„ í†µê³„
    analysis_stats = {
        "total": len(images),
        "success": 0,
        "failed": 0,
        "empty_items": 0,
        "with_items": 0,
        "page_details": []
    }
    
    # 1ë‹¨ê³„: Upstage OCR ìˆœì°¨ ì²˜ë¦¬ (Rate limit ë°©ì§€)
    print(f"ğŸ“ 1ë‹¨ê³„: Upstage OCR ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘ ({len(images)}ê°œ í˜ì´ì§€, ìš”ì²­ ê°„ ë”œë ˆì´: {ocr_delay}ì´ˆ)")
    upstage_extractor = UpstageExtractor()
    ocr_texts = []  # OCR í…ìŠ¤íŠ¸ ì €ì¥
    
    for idx, image in enumerate(images):
        page_num = idx + 1
        total_pages = len(images)
        
        # ì²« ë²ˆì§¸ í˜ì´ì§€ê°€ ì•„ë‹Œ ê²½ìš° ìš”ì²­ ê°„ ë”œë ˆì´ (Rate limit ë°©ì§€)
        if idx > 0 and ocr_delay > 0:
            print(f"\nâ³ {ocr_delay}ì´ˆ ëŒ€ê¸° ì¤‘... (Rate limit ë°©ì§€)", end="", flush=True)
            time.sleep(ocr_delay)
            print(" ì™„ë£Œ")
        
        if progress_callback:
            progress_callback(page_num, total_pages, f"ğŸ” í˜ì´ì§€ {page_num}/{total_pages}: Upstage OCR ì‘ì—… ì¤‘...")
        
        print(f"í˜ì´ì§€ {page_num}/{total_pages} OCR ì¤‘...", end="", flush=True)
        
        tmp_path = None
        try:
            # ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_file:
                image.save(tmp_file.name, "PNG")
                tmp_path = tmp_file.name
            
            # ë””ë²„ê¹…: ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
            try:
                os.makedirs(debug_dir, exist_ok=True)
                debug_image_path = os.path.join(debug_dir, f"page_{page_num}_original_image.png")
                image.save(debug_image_path, "PNG")
                print(f"  ğŸ’¾ ë””ë²„ê¹…: ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ - {debug_image_path}")
            except Exception as debug_error:
                print(f"  âš ï¸ ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {debug_error}")
            
            try:
                ocr_text = upstage_extractor.extract_text(tmp_path)
                if not ocr_text or len(ocr_text.strip()) == 0:
                    raise Exception("OCR í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                
                ocr_texts.append(ocr_text)
                print(f" ì™„ë£Œ")
                
            except Exception as e:
                error_msg = str(e)
                print(f" ì‹¤íŒ¨ - {error_msg}")
                ocr_texts.append(None)  # ì‹¤íŒ¨í•œ í˜ì´ì§€ëŠ” Noneìœ¼ë¡œ í‘œì‹œ
                
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if tmp_path:
                try:
                    os.unlink(tmp_path)
                except Exception:
                    pass
    
    print(f"âœ… OCR ì™„ë£Œ: {len([t for t in ocr_texts if t is not None])}/{len(images)}ê°œ í˜ì´ì§€ ì„±ê³µ\n")
    
    # 2ë‹¨ê³„: RAG+LLM ë³‘ë ¬ ì²˜ë¦¬ (OCR í…ìŠ¤íŠ¸ê°€ ìˆëŠ” í˜ì´ì§€ë§Œ)
    stats_lock = Lock()
    
    def process_rag_llm(idx: int, ocr_text: str) -> tuple[int, Dict[str, Any], Optional[str]]:
        """
        RAG+LLM ì²˜ë¦¬ í•¨ìˆ˜ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
        
        Args:
            idx: í˜ì´ì§€ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
            ocr_text: OCR ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        
        Returns:
            (í˜ì´ì§€ ì¸ë±ìŠ¤, í˜ì´ì§€ JSON ê²°ê³¼, ì—ëŸ¬ ë©”ì‹œì§€) íŠœí”Œ
        """
        page_num = idx + 1
        total_pages = len(images)
        page_detail = {"page_num": page_num, "status": "unknown", "items_count": 0, "error": None}
        
        try:
            if progress_callback:
                progress_callback(page_num, total_pages, f"ğŸ” í˜ì´ì§€ {page_num}/{total_pages}: RAG ê²€ìƒ‰ ì¤‘...")
            
            print(f"í˜ì´ì§€ {page_num}/{total_pages} RAG+LLM ì²˜ë¦¬ ì¤‘...", end="", flush=True)
            
            # RAG ì¶”ì¶œìš© progress_callback ë˜í¼
            def rag_progress_wrapper(msg: str):
                if progress_callback:
                    progress_callback(page_num, total_pages, f"ğŸ¤– í˜ì´ì§€ {page_num}/{total_pages}: {msg}")
            
            page_json = extract_json_with_rag(
                ocr_text=ocr_text,
                question=question,
                model_name=openai_model,
                temperature=0.0,
                top_k=top_k,
                similarity_threshold=similarity_threshold,
                progress_callback=rag_progress_wrapper if progress_callback else None,
                debug_dir=str(debug_dir),
                page_num=page_num
            )
            
            # items ê°œìˆ˜ í™•ì¸ (page_jsonì´ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸)
            if not isinstance(page_json, dict):
                raise Exception(f"ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹: {type(page_json)}. ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            
            items = page_json.get("items", [])
            items_count = len(items) if items else 0
            page_detail["items_count"] = items_count
            
            if items_count > 0:
                page_detail["status"] = "success_with_items"
            else:
                page_detail["status"] = "success_empty"
            
            if progress_callback:
                progress_callback(page_num, total_pages, f"âœ… í˜ì´ì§€ {page_num}/{total_pages} ì™„ë£Œ ({items_count}ê°œ items)")
            
            print(f" ì™„ë£Œ ({items_count}ê°œ items)")
            
            return (idx, page_json, None)
            
        except Exception as e:
            error_msg = str(e)
            print(f" ì‹¤íŒ¨ - {error_msg}")
            if progress_callback:
                progress_callback(page_num, total_pages, f"âŒ í˜ì´ì§€ {page_num}/{total_pages} ì‹¤íŒ¨: {error_msg}")
            
            page_detail["status"] = "failed"
            page_detail["error"] = error_msg
            
            # ì‹¤íŒ¨í•œ í˜ì´ì§€ëŠ” ë¹ˆ ê²°ê³¼ë¡œ ë°˜í™˜
            error_result = {
                "items": [],
                "page_role": "detail",
                "error": error_msg
            }
            return (idx, error_result, error_msg)
        finally:
            # í†µê³„ ì—…ë°ì´íŠ¸ (ìŠ¤ë ˆë“œ ì•ˆì „)
            with stats_lock:
                analysis_stats["page_details"].append(page_detail)
                if page_detail["status"] == "failed":
                    analysis_stats["failed"] += 1
                else:
                    analysis_stats["success"] += 1
                    if page_detail["items_count"] > 0:
                        analysis_stats["with_items"] += 1
                    else:
                        analysis_stats["empty_items"] += 1
    
    # RAG+LLM ë³‘ë ¬ ì²˜ë¦¬
    page_results = {}
    valid_ocr_indices = [(idx, ocr_text) for idx, ocr_text in enumerate(ocr_texts) if ocr_text is not None]
    
    if len(valid_ocr_indices) == 0:
        # OCRì´ ëª¨ë‘ ì‹¤íŒ¨í•œ ê²½ìš°
        print("âš ï¸ ëª¨ë“  í˜ì´ì§€ OCR ì‹¤íŒ¨")
        page_jsons = [{
            "items": [],
            "page_role": "detail",
            "error": "OCR ì‹¤íŒ¨"
        } for _ in range(len(images))]
        return page_jsons, image_paths, pil_images
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì—¬ë¶€ ê²°ì • (ìœ íš¨í•œ OCR í…ìŠ¤íŠ¸ê°€ 2ê°œ ì´ìƒì¼ ë•Œë§Œ ë³‘ë ¬ ì²˜ë¦¬)
    use_parallel_rag = len(valid_ocr_indices) > 1
    
    if use_parallel_rag:
        # ë³‘ë ¬ ì²˜ë¦¬: ThreadPoolExecutor ì‚¬ìš©
        max_workers = min(rag_llm_workers, len(valid_ocr_indices))
        print(f"ğŸš€ 2ë‹¨ê³„: RAG+LLM ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ìµœëŒ€ {max_workers}ê°œ ìŠ¤ë ˆë“œ)")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ìœ íš¨í•œ OCR í…ìŠ¤íŠ¸ì— ëŒ€í•´ Future ì œì¶œ
            future_to_idx = {
                executor.submit(process_rag_llm, idx, ocr_text): idx
                for idx, ocr_text in valid_ocr_indices
            }
            
            # ì™„ë£Œëœ ì‘ì—…ë¶€í„° ì²˜ë¦¬
            completed_count = 0
            for future in as_completed(future_to_idx):
                idx, page_json, error = future.result()
                page_results[idx] = page_json
                completed_count += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if error:
                    print(f"í˜ì´ì§€ {idx+1}/{len(images)} RAG+LLM ì²˜ë¦¬ ì‹¤íŒ¨: {error}")
                
                if progress_callback:
                    progress_callback(completed_count, len(valid_ocr_indices), f"ì§„í–‰ ì¤‘... ({completed_count}/{len(valid_ocr_indices)}ê°œ í˜ì´ì§€ ì™„ë£Œ)")
    else:
        # ìˆœì°¨ ì²˜ë¦¬ (OCR í…ìŠ¤íŠ¸ê°€ 1ê°œì¼ ë•Œ)
        idx, ocr_text = valid_ocr_indices[0]
        idx, page_json, error = process_rag_llm(idx, ocr_text)
        page_results[idx] = page_json
    
    # OCR ì‹¤íŒ¨í•œ í˜ì´ì§€ëŠ” ë¹ˆ ê²°ê³¼ë¡œ ì¶”ê°€
    for idx, ocr_text in enumerate(ocr_texts):
        if ocr_text is None:
            page_results[idx] = {
                "items": [],
                "page_role": "detail",
                "error": "OCR ì‹¤íŒ¨"
            }
    
    # ëª¨ë“  í˜ì´ì§€ ì¸ë±ìŠ¤ê°€ page_resultsì— ìˆëŠ”ì§€ í™•ì¸ (ëˆ„ë½ëœ ê²½ìš° ë¹ˆ ê²°ê³¼ë¡œ ì¶”ê°€)
    for idx in range(len(images)):
        if idx not in page_results:
            page_results[idx] = {
                "items": [],
                "page_role": "detail",
                "error": "ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ"
            }
    
    # ëª¨ë“  í˜ì´ì§€ ì¸ë±ìŠ¤ê°€ page_resultsì— ìˆëŠ”ì§€ í™•ì¸ (ëˆ„ë½ëœ ê²½ìš° ë¹ˆ ê²°ê³¼ë¡œ ì¶”ê°€)
    for idx in range(len(images)):
        if idx not in page_results:
            print(f"âš ï¸ í˜ì´ì§€ {idx+1} ê²°ê³¼ê°€ ì—†ì–´ ë¹ˆ ê²°ê³¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.")
            page_results[idx] = {
                "items": [],
                "page_role": "detail",
                "error": "ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ"
            }
    
    # ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    page_jsons = [page_results[i] for i in range(len(images))]
    
    # ë””ë²„ê¹…: ê²°ê³¼ í™•ì¸
    try:
        print(f"\nğŸ“‹ ìµœì¢… ê²°ê³¼ í™•ì¸: {len(page_jsons)}ê°œ í˜ì´ì§€ ê²°ê³¼ ìƒì„±ë¨")
        for idx, result in enumerate(page_jsons):
            items_count = len(result.get("items", []))
            error = result.get("error")
            status = f"{items_count}ê°œ items" if items_count > 0 else (f"ì˜¤ë¥˜: {error}" if error else "ë¹ˆ ê²°ê³¼")
            print(f"  - í˜ì´ì§€ {idx+1}: {status}")
        
        # ë¶„ì„ í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š RAG ë¶„ì„ í†µê³„:")
        print(f"  - ì „ì²´ í˜ì´ì§€: {analysis_stats['total']}ê°œ")
        print(f"  - ë¶„ì„ ì„±ê³µ: {analysis_stats['success']}ê°œ (items ìˆìŒ: {analysis_stats['with_items']}ê°œ, items ì—†ìŒ: {analysis_stats['empty_items']}ê°œ)")
        print(f"  - ë¶„ì„ ì‹¤íŒ¨: {analysis_stats['failed']}ê°œ")
        print(f"\nğŸ“‹ í˜ì´ì§€ë³„ ìƒì„¸:")
        for detail in analysis_stats.get("page_details", []):
            status_icon = "âœ…" if detail["status"].startswith("success") else "âŒ"
            items_info = f", {detail['items_count']}ê°œ items" if detail["items_count"] > 0 else ""
            error_info = f", ì˜¤ë¥˜: {detail['error']}" if detail.get("error") else ""
            print(f"  {status_icon} í˜ì´ì§€ {detail['page_num']}: {detail['status']}{items_info}{error_info}")
    except Exception as stats_error:
        print(f"\nâš ï¸ í†µê³„ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê²°ê³¼ëŠ” ì •ìƒ ë°˜í™˜): {stats_error}")
        import traceback
        print(f"  - ìƒì„¸:\n{traceback.format_exc()}")
    
    # ë°˜í™˜ê°’ ê²€ì¦
    if page_jsons is None:
        raise ValueError("page_jsonsê°€ Noneì…ë‹ˆë‹¤")
    if not isinstance(page_jsons, list):
        raise ValueError(f"page_jsonsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(page_jsons)}")
    if len(page_jsons) == 0:
        raise ValueError("page_jsonsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
    
    print(f"\nâœ… extract_pages_with_rag ë°˜í™˜ ì¤€ë¹„ ì™„ë£Œ: {len(page_jsons)}ê°œ í˜ì´ì§€, {len(image_paths) if image_paths else 0}ê°œ ì´ë¯¸ì§€ ê²½ë¡œ, {len(pil_images) if pil_images else 0}ê°œ PIL ì´ë¯¸ì§€")
    
    return page_jsons, image_paths, pil_images

