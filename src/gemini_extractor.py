"""
Gemini Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ PDFë¥¼ í˜ì´ì§€ë³„ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë“ˆ

PDF íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ê³ , Gemini Vision APIë¡œ ê° í˜ì´ì§€ë¥¼ ë¶„ì„í•˜ì—¬
êµ¬ì¡°í™”ëœ JSON ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ìºì‹œ ê¸°ëŠ¥ì„ í†µí•´ ì¬í˜„ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
"""

import json
import re
import os
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

from pdf2image import convert_from_path
from PIL import Image, ImageFile

# DecompressionBombWarning ë°©ì§€: ì´ë¯¸ì§€ í¬ê¸° ì œí•œ ì¦ê°€
Image.MAX_IMAGE_PIXELS = None  # ì œí•œ ì—†ìŒ (ë˜ëŠ” ì¶©ë¶„íˆ í° ê°’ìœ¼ë¡œ ì„¤ì •)
ImageFile.LOAD_TRUNCATED_IMAGES = True  # ì†ìƒëœ ì´ë¯¸ì§€ë„ ë¡œë“œ ì‹œë„
import google.generativeai as genai

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ì„ ëª…ì‹œì ìœ¼ë¡œ ë¡œë“œ
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path)  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ


class PDFProcessor:
    """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, dpi: int = 300):
        """
        Args:
            dpi: PDF ë³€í™˜ ì‹œ í•´ìƒë„ (ê¸°ë³¸ê°’: 300)
        """
        self.dpi = dpi
    
    def convert_pdf_to_images(self, pdf_path: str) -> List[Image.Image]:
        """
        PDF íŒŒì¼ì„ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸ (ê° í˜ì´ì§€ë‹¹ í•˜ë‚˜)
        """
        images = convert_from_path(pdf_path, dpi=self.dpi)  # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        return images
    
    def save_images(self, images: List[Image.Image], output_dir: str, prefix: str = "page") -> List[str]:
        """
        ì´ë¯¸ì§€ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            images: PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸
            output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            prefix: íŒŒì¼ëª… ì ‘ë‘ì‚¬ (ê¸°ë³¸ê°’: "page")
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        os.makedirs(output_dir, exist_ok=True)  # ë””ë ‰í† ë¦¬ ìƒì„±
        saved_paths = []
        
        for idx, img in enumerate(images):
            filename = f"{prefix}_{idx+1}.png"
            filepath = os.path.join(output_dir, filename)
            try:
                # ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ê°•ì œë¡œ ë¡œë“œ
                img.load()
                # PNGë¡œ ì €ì¥ (ìµœê³  í’ˆì§ˆ, ì••ì¶• ì—†ìŒ)
                # optimize=Falseë¡œ ìµœì í™” ë¹„í™œì„±í™”í•˜ì—¬ ì›ë³¸ í’ˆì§ˆ ìœ ì§€
                img.save(filepath, "PNG", optimize=False)
                # ì €ì¥ëœ íŒŒì¼ì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
                    saved_paths.append(filepath)
                else:
                    print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {filepath} (íŒŒì¼ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤)")
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({filepath}): {e}")
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                if os.path.exists(filepath):
                    saved_paths.append(filepath)
        
        return saved_paths


class GeminiVisionParser:
    """Gemini Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ íŒŒì‹±"""
    
    def __init__(self, api_key: Optional[str] = None, model_name: str = "gemini-3-pro-preview"):
        """
        Args:
            api_key: Google Gemini API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
            model_name: ì‚¬ìš©í•  Gemini ëª¨ë¸ ì´ë¦„
        """
        if api_key is None:
            api_key = os.getenv("GEMINI_API_KEY")  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
            if not api_key:
                raise ValueError("GEMINI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•˜ì„¸ìš”.")
        
        genai.configure(api_key=api_key)  # API í‚¤ ì„¤ì •
        
        # ì•ˆì „ì„± ì„¤ì •: ë¬¸ì„œ ë¶„ì„ì„ ìœ„í•´ í•„í„° ì™„í™”
        safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_NONE"
            }
        ]
        
        self.model = genai.GenerativeModel(
            model_name=model_name,
            safety_settings=safety_settings
        )  # Gemini ëª¨ë¸ ì´ˆê¸°í™”
        self.model_name = model_name
    
    def get_parsing_prompt(self) -> str:
        """
        Gemini Visionì„ ìœ„í•œ êµ¬ì¡°í™” íŒŒì‹± í”„ë¡¬í”„íŠ¸
        
        Returns:
            íŒŒì‹± í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        prompt = """ì´ ì´ë¯¸ì§€ëŠ” ì¼ë³¸ì–´ ì¡°ê±´ì²­êµ¬ì„œ(æ¡ä»¶è«‹æ±‚æ›¸) ë¬¸ì„œì…ë‹ˆë‹¤.
ìì—°ì–´ ê¸°ë°˜ ì¶”ë¡ ì„ í†µí•´ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

{
  "text": "ì „ì²´ í…ìŠ¤íŠ¸ ë‚´ìš© (ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ)",
  "document_number": "ë¬¸ì„œ ë²ˆí˜¸ (ë¬¸ì„œ ìƒë‹¨ì˜ No, è«‹æ±‚æ›¸No ë“± - í˜ì´ì§€ë‹¹ í•˜ë‚˜)",
  "customer": "ê±°ë˜ì²˜(ìµœì¢… íŒë§¤ì²˜) - ìƒí’ˆì„ ìµœì¢… íŒë§¤í•˜ëŠ” ì†Œë§¤ ì²´ì¸ (ì˜ˆ: ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãƒãƒ¼ãƒˆ, ã‚»ãƒ–ãƒ³ã‚¤ãƒ¬ãƒ–ãƒ³, ãƒ­ãƒ”ã‚¢, ã‚¹ãƒ¼ãƒ‘ãƒ¼ ë“±) - ë‹¤ì–‘í•œ í‘œí˜„ ì¸ì‹ (å¾—æ„å…ˆ, è«‹æ±‚å…ˆ, ç´å“å…ˆ, å®¢å…ˆ ë“±)",
  "issuer": "ë°œí–‰ì²˜ - ë‹¤ì–‘í•œ í‘œí˜„ ì¸ì‹ (ç™ºè¡Œè€…, ä»•å…¥å…ˆ, å£²æ–¹, ä¾›çµ¦å…ƒ ë“±)",
  "issue_date": "ë°œí–‰ì¼ (ä½œæˆæ—¥, ç™ºè¡Œæ—¥ ë“±)",
  "billing_period": "ì²­êµ¬ê¸°ê°„ (è«‹æ±‚æœŸé–“, ã”è«‹æ±‚æœŸé–“ ë“±)",
  "total_amount": "ì´ ê¸ˆì•¡ (é‡‘é¡, åˆè¨ˆ, ç·é¡, è«‹æ±‚é‡‘é¡ ë“±)",
  "items": [
    {
      "management_id": "ê´€ë¦¬ë²ˆí˜¸ - ê° í–‰/í•­ëª©ë§ˆë‹¤ ë‹¤ë¥¸ ê´€ë¦¬ë²ˆí˜¸ê°€ ìˆì„ ìˆ˜ ìˆìŒ (è«‹æ±‚No, å¥‘ç´„No, ç®¡ç†ç•ªå·, ä¼ç¥¨ç•ªå· ë“±)",
      "product_name": "ìƒí’ˆëª… (å•†å“å, å“å, ä»¶å ë“±) - ì œí’ˆë²ˆí˜¸(13ìë¦¬ ìˆ«ì ë°”ì½”ë“œ, ì˜ˆ: 8801043157506)ê°€ ì•ì— ìˆìœ¼ë©´ ì œì™¸í•˜ê³  ìˆœìˆ˜ ìƒí’ˆëª…ë§Œ ì¶”ì¶œ",
      "quantity": "ìˆ˜ëŸ‰ (ç›´æ¥çš„ãªæ•°é‡ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ ê²½ìš°ã®ã¿ã€æ•°å€¤ã€‚ã‚±ãƒ¼ã‚¹/ãƒãƒ©ã§è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ null)",
      "case_count": "ã‚±ãƒ¼ã‚¹æ•° (ã‚±ãƒ¼ã‚¹å˜ä½ã®æ•°é‡ã€ä¾‹: 58ã‚±ãƒ¼ã‚¹ â†’ 58, ãªã„å ´åˆã¯ null)",
      "bara_count": "ãƒãƒ©æ•° (ãƒãƒ©å˜ä½ã®æ•°é‡ã€ä¾‹: 6ãƒãƒ© â†’ 6, ãªã„å ´åˆã¯ null)",
      "units_per_case": "ã‚±ãƒ¼ã‚¹å†…å…¥æ•° (ì¼€ì´ìŠ¤ë‹¹ ê°œìˆ˜) - ì˜ˆ: 12x1ì´ë©´ 12, 30x1ì´ë©´ 30, 12x2ì´ë©´ 24 (ì—†ìœ¼ë©´ null)",
      "amount": "ê¸ˆì•¡ (é‡‘é¡, ç¨è¾¼é‡‘é¡ ë“±)",
      "customer": "í•­ëª©ë³„ ê±°ë˜ì²˜(ìµœì¢… íŒë§¤ì²˜) - í•´ë‹¹ í•­ëª©ì˜ ê±°ë˜ì²˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ (ì—†ìœ¼ë©´ null)"
    }
  ],
  "page_role": "í˜ì´ì§€ ì—­í•  íŒë‹¨: cover(í‘œì§€), main(ë³¸ë¬¸), detail(ìƒì„¸ë‚´ì—­), reply(íšŒì‹ ì„œ)"
}

í‘œ êµ¬ì¡° ì¸ì‹ ë° ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì¶œ:
- ë¬¸ì„œì— í‘œ(í…Œì´ë¸”)ê°€ ìˆëŠ” ê²½ìš°, í‘œì˜ ì»¬ëŸ¼ í—¤ë”ë¥¼ ë¨¼ì € ì¸ì‹í•©ë‹ˆë‹¤.
- í‘œì˜ ê° í–‰(è¡Œ)ì€ í•˜ë‚˜ì˜ itemì— í•´ë‹¹í•©ë‹ˆë‹¤.
- í‘œì˜ ì»¬ëŸ¼ ìœ„ì¹˜ì— ë”°ë¼ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤:
  * "è«‹æ±‚No", "å¥‘ç´„No", "ç®¡ç†ç•ªå·", "ä¼ç¥¨ç•ªå·" ë“±ì˜ ì»¬ëŸ¼ â†’ management_id (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "å–å¼•å…ˆ", "å¾—æ„å…ˆ", "è«‹æ±‚å…ˆ", "ç´å“å…ˆ", "å®¢å…ˆ" ë“±ì˜ ì»¬ëŸ¼ â†’ customer (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’, ìœ„ì¹˜ìƒ ë§ìœ¼ë©´ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œ)
  * "å•†å“å", "å“å", "ä»¶å" ë“±ì˜ ì»¬ëŸ¼ â†’ product_name (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "ã‚±ãƒ¼ã‚¹å†…å…¥æ•°" ì»¬ëŸ¼ â†’ units_per_case (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "æ•°é‡" ì»¬ëŸ¼ì˜ "ã‚±ãƒ¼ã‚¹" í•˜ìœ„ ê°’ â†’ case_count (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "æ•°é‡" ì»¬ëŸ¼ì˜ "ãƒãƒ©" í•˜ìœ„ ê°’ â†’ bara_count (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
  * "è«‹æ±‚é‡‘é¡", "é‡‘é¡", "ç¨è¾¼é‡‘é¡" ë“±ì˜ ì»¬ëŸ¼ â†’ amount (í•´ë‹¹ í–‰ì˜ í•´ë‹¹ ì»¬ëŸ¼ ê°’)
- í‘œì—ì„œ "å–å¼•å…ˆ" ì»¬ëŸ¼ì— ìˆëŠ” ê°’ì€ ê·¸ ìœ„ì¹˜ìƒ ê±°ë˜ì²˜ëª…ì´ë¯€ë¡œ, ì˜ë¯¸ íŒë‹¨ë³´ë‹¤ ìœ„ì¹˜ ì •ë³´ë¥¼ ìš°ì„ í•˜ì—¬ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ê°™ì€ management_idë¥¼ ê°€ì§„ ì—¬ëŸ¬ í–‰ì´ ê°™ì€ customer ê°’ì„ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ê·¸ë£¹ ë‹¨ìœ„ë¡œ í‘œì‹œë˜ëŠ” ê²½ìš°).

ì¶”ì¶œ ê°€ì´ë“œ:
- customerëŠ” ìµœì¢… íŒë§¤ì²˜(ìµœì¢… ì†Œë§¤ ì²´ì¸)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‹ë³„í•©ë‹ˆë‹¤. ì˜ˆ: ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãƒãƒ¼ãƒˆ, ã‚»ãƒ–ãƒ³ã‚¤ãƒ¬ãƒ–ãƒ³, ãƒ­ãƒ”ã‚¢, ã‚¹ãƒ¼ãƒ‘ãƒ¼ ë“±
- customerëŠ” íŒ¨ë°€ë¦¬ë§ˆíŠ¸, ì„¸ë¸ì¼ë ˆë¸, ìŠˆí¼ ë“± ìµœì¢… íŒë§¤ì²˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ë©°, ë„ë§¤ìƒ(å¸), ë¬¼ë¥˜ì„¼í„°, ë°°ì†¡ì²˜ëŠ” customerë¡œ ë¶„ë¥˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì…ì¶œí•˜ì„¼í„°(å…¥å‡ºè·ã‚»ãƒ³ã‚¿ãƒ¼), ë¬¼ë¥˜ì„¼í„°(ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼), ë°°ì†¡ì²˜(é…é€å…ˆ) ë“±ì˜ ì •ë³´ëŠ” ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- management_idëŠ” ê° í•­ëª©(items)ë§ˆë‹¤ ì¶”ì¶œí•©ë‹ˆë‹¤. í•œ í˜ì´ì§€ì— ì—¬ëŸ¬ ê´€ë¦¬ë²ˆí˜¸ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- í‘œë‚˜ í…Œì´ë¸”ì˜ ê° í–‰ë§ˆë‹¤ management_id(è«‹æ±‚No, å¥‘ç´„No ë“±)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ê° í•­ëª©(items)ë§ˆë‹¤ customerê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•­ëª©ë³„ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
- document_numberëŠ” ë¬¸ì„œ ì „ì²´ë¥¼ ì‹ë³„í•˜ëŠ” ë²ˆí˜¸ì´ê³ , management_idëŠ” ê° í•­ëª©/ê³„ì•½ì„ ì‹ë³„í•˜ëŠ” ë²ˆí˜¸ì…ë‹ˆë‹¤.
- quantityëŠ” ì§ì ‘ì ì¸ ìˆ˜ëŸ‰ì´ ëª…ì‹œë˜ì–´ ìˆì„ ë•Œë§Œ ìˆ«ìë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. ì˜ˆ: "100å€‹" â†’ 100, "50æœ¬" â†’ 50. ì¼€ì´ìŠ¤/ë°”ë¼ë¡œë§Œ í‘œì‹œëœ ê²½ìš°ëŠ” nullì…ë‹ˆë‹¤.
- case_countëŠ” ì¼€ì´ìŠ¤ ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆ: "58ã‚±ãƒ¼ã‚¹ 6ãƒãƒ©" â†’ case_count: 58, "67ã‚±ãƒ¼ã‚¹ 0ãƒãƒ©" â†’ case_count: 67. ì¼€ì´ìŠ¤ ì •ë³´ê°€ ì—†ìœ¼ë©´ nullì…ë‹ˆë‹¤.
- bara_countëŠ” ë°”ë¼ ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆ: "58ã‚±ãƒ¼ã‚¹ 6ãƒãƒ©" â†’ bara_count: 6, "67ã‚±ãƒ¼ã‚¹ 0ãƒãƒ©" â†’ bara_count: 0 ë˜ëŠ” null. ë°”ë¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ nullì…ë‹ˆë‹¤.
- units_per_case(ã‚±ãƒ¼ã‚¹å†…å…¥æ•°)ëŠ” ì¼€ì´ìŠ¤ë‹¹ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. "12x1"ì´ë©´ 12, "30x1"ì´ë©´ 30, "12x2"ì´ë©´ 24ì…ë‹ˆë‹¤. í…Œì´ë¸”ì˜ "ã‚±ãƒ¼ã‚¹å†…å…¥æ•°" ì»¬ëŸ¼ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.
- product_nameì—ì„œ ì œí’ˆë²ˆí˜¸(13ìë¦¬ ìˆ«ì ë°”ì½”ë“œ, ì˜ˆ: 8801043157506)ê°€ ì•ì— ìˆìœ¼ë©´ ì œê±°í•˜ê³  ìˆœìˆ˜ ìƒí’ˆëª…ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. ì˜ˆ: "8801043157506 ãƒã‚¦ã‚·ãƒ³ è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ 3é£Ÿ" â†’ "ãƒã‚¦ã‚·ãƒ³ è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ 3é£Ÿ", "8801043030694 è¾²å¿ƒ NEWè¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ã‚«ãƒƒãƒ— 68g" â†’ "è¾²å¿ƒ NEWè¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ã‚«ãƒƒãƒ— 68g"
- í‘œí˜„ì´ ë‹¤ì–‘í•´ë„ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ê°™ì€ í•„ë“œë¡œ ì¸ì‹í•©ë‹ˆë‹¤ (ì˜ˆ: è«‹æ±‚Noì™€ å¥‘ç´„NoëŠ” ëª¨ë‘ management_id)
- ì •ë³´ê°€ ì—†ìœ¼ë©´ nullì„ ì‚¬ìš©í•©ë‹ˆë‹¤
- JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³  ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ì¶”ê°€ ì¶”ì¶œ ê·œì¹™:
- í‘œì—ì„œ "å–å¼•å…ˆ" ì»¬ëŸ¼ ìœ„ì¹˜ì— ìˆëŠ” ê°’ì€ ìœ„ì¹˜ìƒ ê±°ë˜ì²˜ëª…ì´ë¯€ë¡œ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. ì˜ë¯¸ íŒë‹¨ë³´ë‹¤ ìœ„ì¹˜ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•©ë‹ˆë‹¤.
- customerëŠ” ìµœì¢… íŒë§¤ì²˜(ìµœì¢… ì†Œë§¤ ì²´ì¸)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ë©°, í‘œì˜ "å–å¼•å…ˆ" ì»¬ëŸ¼ì— ëª…ì‹œëœ ê°’ì€ ê·¸ ìœ„ì¹˜ìƒ ê±°ë˜ì²˜ëª…ì´ë¯€ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ë„ë§¤ìƒ(å¸), ë¬¼ë¥˜ì„¼í„°, ë°°ì†¡ì½”ë“œê°€ ìˆëŠ” ì‚¬ì—…ì†Œ, ì…ì¶œí•˜ì„¼í„°(å…¥å‡ºè·ã‚»ãƒ³ã‚¿ãƒ¼), ë¬¼ë¥˜ì„¼í„°(ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼)ëŠ” customerë¡œ ë¶„ë¥˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- í‘œì˜ "å–å¼•å…ˆ" ì»¬ëŸ¼ì— ìˆëŠ” ê°’ì€ ìœ„ì¹˜ìƒ ê±°ë˜ì²˜ëª…ì´ë¯€ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""
        return prompt
    
    def parse_image(self, image: Image.Image, max_size: int = 600) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ë¥¼ Gemini Visionìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ JSON ë°˜í™˜
        
        Args:
            image: PIL Image ê°ì²´
            max_size: Gemini APIì— ì „ë‹¬í•  ìµœëŒ€ ì´ë¯¸ì§€ í¬ê¸° (í”½ì…€, ê¸°ë³¸ê°’: 1024)
                      ì†ë„ ê°œì„ ì„ ìœ„í•´ í° ì´ë¯¸ì§€ëŠ” ë¦¬ì‚¬ì´ì¦ˆë¨
                      ë” ì‘ê²Œ í•˜ë ¤ë©´ 800, 600 ë“±ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥
            
        Returns:
            íŒŒì‹± ê²°ê³¼ JSON ë”•ì…”ë„ˆë¦¬
        """
        # ì›ë³¸ ì´ë¯¸ì§€ ì •ë³´
        original_width, original_height = image.size
        
        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (Gemini API ì†ë„ ê°œì„ ì„ ìœ„í•´)
        api_image = image
        if original_width > max_size or original_height > max_size:
            # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
            ratio = min(max_size / original_width, max_size / original_height)
            new_width = int(original_width * ratio)
            new_height = int(original_height * ratio)
            api_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            print(f"  ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ: {original_width}x{original_height}px â†’ {new_width}x{new_height}px", end="", flush=True)
        else:
            print(f"  ì´ë¯¸ì§€ í¬ê¸°: {original_width}x{original_height}px", end="", flush=True)
        
        # Gemini API í˜¸ì¶œ: ì¬ì‹œë„ ë¡œì§ í¬í•¨ (SAFETY ì˜¤ë¥˜ ëŒ€ì‘)
        max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        retry_delay = 2  # ì¬ì‹œë„ ì „ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        
        for attempt in range(max_retries):
            try:
                # ì´ë¯¸ì§€ë§Œ ë¨¼ì € ì „ë‹¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹œë„
                chat = self.model.start_chat(history=[])
                # 1ë‹¨ê³„: ì´ë¯¸ì§€ë§Œ ë¨¼ì € ì „ë‹¬ (í”„ë¡¬í”„íŠ¸ ì—†ì´)
                _ = chat.send_message([api_image])
                # 2ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ë¥¼ ë³„ë„ ë©”ì‹œì§€ë¡œ ì „ë‹¬
                response = chat.send_message(self.get_parsing_prompt())
                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ
            except Exception as e:
                error_msg = str(e)
                # SAFETY ì˜¤ë¥˜ì¸ ê²½ìš° ì¬ì‹œë„
                if "SAFETY" in error_msg or "å®‰å…¨æ€§" in error_msg or "finish_reason: SAFETY" in error_msg:
                    if attempt < max_retries - 1:
                        print(f"  âš ï¸ SAFETY í•„í„° ê°ì§€ (ì‹œë„ {attempt + 1}/{max_retries}), {retry_delay}ì´ˆ í›„ ì¬ì‹œë„...", end="", flush=True)
                        time.sleep(retry_delay)
                        retry_delay *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„
                        continue
                    else:
                        # ë§ˆì§€ë§‰ ì‹œë„ë„ ì‹¤íŒ¨í•˜ë©´ ì˜ˆì™¸ ë°œìƒ
                        raise Exception(f"SAFETY í•„í„°ë¡œ ì¸í•´ {max_retries}íšŒ ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨: {error_msg}")
                else:
                    # SAFETY ì˜¤ë¥˜ê°€ ì•„ë‹ˆë©´ ì¦‰ì‹œ ì˜ˆì™¸ ë°œìƒ
                    raise
        
        # ì‘ë‹µ ê²€ì¦
        if not response.candidates:
            raise Exception("Gemini API ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        candidate = response.candidates[0]
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ (contentê°€ ìˆìœ¼ë©´ finish_reasonê³¼ ê´€ê³„ì—†ì´ ì¶”ì¶œ)
        if not candidate.content or not candidate.content.parts:
            raise Exception("Gemini API ì‘ë‹µì— content partsê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        result_text = ""
        for part in candidate.content.parts:
            if hasattr(part, 'text') and part.text:
                result_text += part.text
        
        if not result_text:
            raise Exception("Gemini API ì‘ë‹µì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # JSON ì¶”ì¶œ ì‹œë„
        try:
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            json_match = re.search(r'\{.*\}', result_text, re.DOTALL)  # JSON ê°ì²´ ì¶”ì¶œ
            if json_match:
                result_json = json.loads(json_match.group())  # JSON íŒŒì‹±
                return result_json
            else:
                # JSONì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
                return {"text": result_text}
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
            return {"text": result_text}


def get_gemini_cache_path(pdf_path: str, history_dir: Optional[str] = None) -> str:
    """
    Gemini ê²°ê³¼ ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        history_dir: íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
        
    Returns:
        ìºì‹œ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: "ì¡°ê±´ì²­êµ¬ì„œâ‘¡_gemini_cache.json" ë˜ëŠ” "history/20240101_120000/ì¡°ê±´ì²­êµ¬ì„œâ‘¡_gemini_cache.json")
    """
    pdf_name = Path(pdf_path).stem  # í™•ì¥ì ì œê±°
    cache_filename = f"{pdf_name}_gemini_cache.json"
    
    if history_dir:
        return os.path.join(history_dir, cache_filename)
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ìƒì„±
    # gemini_extractor.pyëŠ” Rebate/src/ ë””ë ‰í† ë¦¬ì— ìˆìœ¼ë¯€ë¡œ parent.parentê°€ í”„ë¡œì íŠ¸ ë£¨íŠ¸
    project_root = Path(__file__).parent.parent.resolve()
    return str(project_root / cache_filename)


def create_history_dir(base_dir: str, pdf_name: str) -> str:
    """
    íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
    
    Args:
        base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ì˜ˆ: "raw_data" ë˜ëŠ” í˜„ì¬ ë””ë ‰í† ë¦¬)
        pdf_name: PDF íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        
    Returns:
        ìƒì„±ëœ íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: "raw_data/ì¡°ê±´ì²­êµ¬ì„œâ‘¡/history/20240101_120000")
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    history_base = os.path.join(base_dir, f"{pdf_name}_history")
    history_dir = os.path.join(history_base, timestamp)
    os.makedirs(history_dir, exist_ok=True)
    return history_dir


def migrate_existing_to_history(base_dir: str, pdf_name: str) -> Optional[str]:
    """
    ê¸°ì¡´ íŒŒì‹± ê²°ê³¼ë¥¼ ì²« ë²ˆì§¸ íˆìŠ¤í† ë¦¬ë¡œ ì´ë™
    
    Args:
        base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬
        pdf_name: PDF íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        
    Returns:
        ìƒì„±ëœ íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ None)
    """
    import shutil
    
    # ê¸°ì¡´ ìºì‹œ íŒŒì¼ ì°¾ê¸°
    cache_filename = f"{pdf_name}_gemini_cache.json"
    possible_cache_paths = [
        cache_filename,  # í˜„ì¬ ë””ë ‰í† ë¦¬
        os.path.join(base_dir, cache_filename),  # base_dir
        os.path.join("raw_data", cache_filename),  # raw_data
    ]
    
    existing_cache_path = None
    for cache_path in possible_cache_paths:
        if os.path.exists(cache_path):
            existing_cache_path = cache_path
            break
    
    # ê¸°ì¡´ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì°¾ê¸°
    image_dir_name = f"{pdf_name}_images"
    possible_image_dirs = [
        os.path.join(base_dir, image_dir_name),
        os.path.join("raw_data", image_dir_name),
        image_dir_name,
    ]
    
    existing_image_dir = None
    for img_dir in possible_image_dirs:
        if os.path.exists(img_dir) and os.path.isdir(img_dir):
            existing_image_dir = img_dir
            break
    
    # ê¸°ì¡´ íŒŒì¼ì´ ì—†ìœ¼ë©´ None ë°˜í™˜
    if not existing_cache_path and not existing_image_dir:
        return None
    
    # íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„± (ì˜¤ë˜ëœ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ - ì²« ë²ˆì§¸ íˆìŠ¤í† ë¦¬)
    # íŒŒì¼ ìˆ˜ì • ì‹œê°„ì„ ì‚¬ìš©í•˜ê±°ë‚˜, ì˜¤ë˜ëœ ë‚ ì§œë¡œ ì„¤ì •
    if existing_cache_path:
        file_time = os.path.getmtime(existing_cache_path)
        timestamp = datetime.fromtimestamp(file_time).strftime("%Y%m%d_%H%M%S")
    elif existing_image_dir:
        # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ì˜ ì²« ë²ˆì§¸ íŒŒì¼ ì‹œê°„ ì‚¬ìš©
        image_files = [f for f in os.listdir(existing_image_dir) if f.endswith('.png')]
        if image_files:
            first_image = os.path.join(existing_image_dir, sorted(image_files)[0])
            file_time = os.path.getmtime(first_image)
            timestamp = datetime.fromtimestamp(file_time).strftime("%Y%m%d_%H%M%S")
        else:
            timestamp = "19700101_000000"  # ê¸°ë³¸ê°’
    else:
        timestamp = "19700101_000000"  # ê¸°ë³¸ê°’
    
    history_base = os.path.join(base_dir, f"{pdf_name}_history")
    history_dir = os.path.join(history_base, timestamp)
    
    # ì´ë¯¸ íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if os.path.exists(history_dir):
        return history_dir
    
    os.makedirs(history_dir, exist_ok=True)
    
    # ìºì‹œ íŒŒì¼ ë³µì‚¬
    if existing_cache_path:
        dest_cache = os.path.join(history_dir, cache_filename)
        if not os.path.exists(dest_cache):
            shutil.copy2(existing_cache_path, dest_cache)
            print(f"ğŸ“¦ ê¸°ì¡´ ìºì‹œë¥¼ íˆìŠ¤í† ë¦¬ë¡œ ë³µì‚¬: {existing_cache_path} â†’ {dest_cache}")
    
    # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ë³µì‚¬
    if existing_image_dir:
        dest_image_dir = os.path.join(history_dir, "images")
        if not os.path.exists(dest_image_dir):
            shutil.copytree(existing_image_dir, dest_image_dir)
            print(f"ğŸ“¦ ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ íˆìŠ¤í† ë¦¬ë¡œ ë³µì‚¬: {existing_image_dir} â†’ {dest_image_dir}")
    
    return history_dir


def list_history_dirs(base_dir: str, pdf_name: str) -> List[Dict[str, Any]]:
    """
    íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ëª©ë¡ ì¡°íšŒ
    
    Args:
        base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬
        pdf_name: PDF íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        
    Returns:
        íˆìŠ¤í† ë¦¬ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{"timestamp": "...", "path": "...", "datetime": datetime}]
    """
    history_base = os.path.join(base_dir, f"{pdf_name}_history")
    if not os.path.exists(history_base):
        return []
    
    histories = []
    for item in sorted(os.listdir(history_base), reverse=True):  # ìµœì‹ ìˆœ
        item_path = os.path.join(history_base, item)
        if os.path.isdir(item_path):
            try:
                # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
                dt = datetime.strptime(item, "%Y%m%d_%H%M%S")
                histories.append({
                    "timestamp": item,
                    "path": item_path,
                    "datetime": dt,
                    "display": dt.strftime("%Y-%m-%d %H:%M:%S")
                })
            except ValueError:
                continue
    
    return histories


def get_image_output_dir(pdf_path: str) -> str:
    """
    ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ ìƒì„± (ìƒˆ êµ¬ì¡°: img/{pdf_name}/)
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ (ë˜ëŠ” íŒŒì¼ëª…ë§Œ)
        
    Returns:
        ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ (img/{pdf_name}/)
    """
    from storage_utils import get_img_dir
    pdf_name = Path(pdf_path).stem  # í™•ì¥ì ì œê±°
    return get_img_dir(pdf_name)


def load_gemini_cache(cache_path: str) -> Optional[List[Dict[str, Any]]]:
    """
    Gemini ê²°ê³¼ ìºì‹œ íŒŒì¼ ë¡œë“œ
    
    Args:
        cache_path: ìºì‹œ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        í˜ì´ì§€ JSON ë¦¬ìŠ¤íŠ¸ (íŒŒì¼ì´ ì—†ìœ¼ë©´ None)
    """
    if os.path.exists(cache_path):
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                data = json.load(f)  # JSON ë¡œë“œ
                # ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict) and "pages" in data:
                    return data["pages"]
                else:
                    return [data] if data else None
        except Exception as e:
            print(f"ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    return None


def save_gemini_cache(cache_path: str, page_jsons: List[Dict[str, Any]]):
    """
    Gemini ê²°ê³¼ë¥¼ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥ (ë¹„í™œì„±í™”ë¨ - DB ì‚¬ìš©)
    
    Args:
        cache_path: ìºì‹œ íŒŒì¼ ê²½ë¡œ (ìƒëŒ€ ë˜ëŠ” ì ˆëŒ€ ê²½ë¡œ) - ì‚¬ìš© ì•ˆ í•¨
        page_jsons: í˜ì´ì§€ JSON ë¦¬ìŠ¤íŠ¸ - ì‚¬ìš© ì•ˆ í•¨
    
    Note:
        ë¡œì»¬ íŒŒì¼ ì €ì¥ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ë¹„í™œì„±í™”ë¨.
        ëª¨ë“  ë°ì´í„°ëŠ” DBì— ì €ì¥ë©ë‹ˆë‹¤.
    """
    # ë¡œì»¬ íŒŒì¼ ì €ì¥ ë¹„í™œì„±í™” (DB ì‚¬ìš©)
    pass


def extract_pages_with_gemini(
    pdf_path: str,
    gemini_api_key: Optional[str] = None,
    gemini_model: str = "gemini-3-pro-preview",
        dpi: int = 300,
    use_gemini_cache: bool = True,
    gemini_cache_path: Optional[str] = None,
    save_images: bool = True,
    image_output_dir: Optional[str] = None,
    use_history: bool = True,
    history_dir: Optional[str] = None
) -> tuple[List[Dict[str, Any]], List[str]]:
    """
    PDF íŒŒì¼ì„ Geminië¡œ ë¶„ì„í•˜ì—¬ í˜ì´ì§€ë³„ JSON ê²°ê³¼ ë°˜í™˜
    
    Gemini í˜¸ì¶œ ë° ê²°ê³¼ ì €ì¥ê¹Œì§€ë§Œ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        gemini_api_key: Gemini API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
        gemini_model: Gemini ëª¨ë¸ ì´ë¦„
        dpi: PDF ë³€í™˜ í•´ìƒë„ (ê¸°ë³¸ê°’: 300)
        use_gemini_cache: Gemini ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        gemini_cache_path: Gemini ìºì‹œ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        save_images: ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        image_output_dir: ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ìë™ ìƒì„±)
        use_history: íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        history_dir: íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ìë™ ìƒì„±)
        
    Returns:
        (í˜ì´ì§€ë³„ Gemini íŒŒì‹± ê²°ê³¼ JSON ë¦¬ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
    """
    pdf_name = Path(pdf_path).stem
    base_dir = os.path.dirname(os.path.abspath(pdf_path)) or os.getcwd()
    if not base_dir:
        base_dir = os.getcwd()
    
    # íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„± (ìƒˆ íŒŒì‹±ì¸ ê²½ìš°)
    if use_history and history_dir is None:
        history_dir = create_history_dir(base_dir, pdf_name)
        print(f"ğŸ“š íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„±: {history_dir}")
    
    # ê¸°ì¡´ ìºì‹œ íŒŒì¼ì„ íˆìŠ¤í† ë¦¬ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ (ì²« íŒŒì‹±ì¸ ê²½ìš°)
    if use_history and history_dir:
        # ê¸°ì¡´ ìºì‹œ íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆìœ¼ë©´ íˆìŠ¤í† ë¦¬ë¡œ ì´ë™
        existing_cache_path = get_gemini_cache_path(pdf_path)  # íˆìŠ¤í† ë¦¬ ì—†ì´ ìƒì„±
        if os.path.exists(existing_cache_path) and os.path.abspath(existing_cache_path) != os.path.abspath(get_gemini_cache_path(pdf_path, history_dir)):
            # ê¸°ì¡´ ìºì‹œë¥¼ íˆìŠ¤í† ë¦¬ë¡œ ë³µì‚¬ (ì²« ë²ˆì§¸ íˆìŠ¤í† ë¦¬ë¡œ)
            import shutil
            history_cache_path = get_gemini_cache_path(pdf_path, history_dir)
            if not os.path.exists(history_cache_path):
                try:
                    shutil.copy2(existing_cache_path, history_cache_path)
                    print(f"ğŸ“¦ ê¸°ì¡´ ìºì‹œë¥¼ íˆìŠ¤í† ë¦¬ë¡œ ë³µì‚¬: {existing_cache_path} â†’ {history_cache_path}")
                except Exception as e:
                    print(f"âš ï¸ íˆìŠ¤í† ë¦¬ ë³µì‚¬ ì‹¤íŒ¨: {e}")
    
    # Gemini ìºì‹œ ê²½ë¡œ ê²°ì • (íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ìš°ì„  ì‚¬ìš©)
    if use_history and history_dir:
        # use_history=Trueì´ê³  history_dirì´ ìˆìœ¼ë©´ í•­ìƒ íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ë‚´ë¶€ ê²½ë¡œ ì‚¬ìš©
        gemini_cache_path = get_gemini_cache_path(pdf_path, history_dir)
    elif gemini_cache_path is None:
        # íˆìŠ¤í† ë¦¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê±°ë‚˜ history_dirì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
        gemini_cache_path = get_gemini_cache_path(pdf_path)
    
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥
    abs_cache_path = os.path.abspath(gemini_cache_path)
    print(f"ğŸ“ ìºì‹œ íŒŒì¼ ê²½ë¡œ: {abs_cache_path}")
    
    # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ê²°ì • (íˆìŠ¤í† ë¦¬ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
    if image_output_dir is None:
        if use_history and history_dir:
            image_output_dir = os.path.join(history_dir, "images")
        else:
            image_output_dir = get_image_output_dir(pdf_path)
    abs_image_dir = os.path.abspath(image_output_dir)
    print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬: {abs_image_dir}")
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    image_paths = []
    
    # 1. Gemini ê²°ê³¼ ë¡œë“œ ë˜ëŠ” ìƒì„±
    page_jsons = None
    if use_gemini_cache:
        page_jsons = load_gemini_cache(gemini_cache_path)  # ìºì‹œì—ì„œ ë¡œë“œ ì‹œë„
        if page_jsons:
            print(f"ğŸ’¾ ê¸°ì¡´ ìºì‹œ ë¡œë“œ: {len(page_jsons)}ê°œ í˜ì´ì§€")
            
            # ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸ (ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆìœ¼ë©´)
            if save_images and os.path.exists(abs_image_dir):
                for idx in range(len(page_jsons)):
                    img_path = os.path.join(abs_image_dir, f"page_{idx+1}.png")
                    if os.path.exists(img_path):
                        image_paths.append(img_path)
                    else:
                        image_paths.append(None)  # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ None
    
    # ìºì‹œê°€ ì—†ìœ¼ë©´ Gemini API í˜¸ì¶œ
    if page_jsons is None:
        # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        pdf_processor = PDFProcessor(dpi=dpi)  # PDF ì²˜ë¦¬ê¸° ìƒì„±
        images = pdf_processor.convert_pdf_to_images(pdf_path)  # PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
        print(f"PDF ë³€í™˜ ì™„ë£Œ: {len(images)}ê°œ í˜ì´ì§€")
        
        # ì´ë¯¸ì§€ ì €ì¥ (ê³ í™”ì§ˆ)
        if save_images:
            print(f"ğŸ’¾ ì´ë¯¸ì§€ ì €ì¥ ì¤‘... ({abs_image_dir})")
            image_paths = pdf_processor.save_images(images, abs_image_dir, prefix="page")
            print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {len(image_paths)}ê°œ íŒŒì¼")
        else:
            image_paths = [None] * len(images)  # ì €ì¥í•˜ì§€ ì•Šìœ¼ë©´ None ë¦¬ìŠ¤íŠ¸
        
        # Gemini Visionìœ¼ë¡œ ê° í˜ì´ì§€ íŒŒì‹±
        gemini_parser = GeminiVisionParser(api_key=gemini_api_key, model_name=gemini_model)  # Gemini íŒŒì„œ ìƒì„±
        page_jsons = []
        
        # ê¸°ì¡´ ìºì‹œê°€ ìˆìœ¼ë©´ ë¡œë“œ (ë¶€ë¶„ì ìœ¼ë¡œ ì €ì¥ëœ ê²½ìš° ì¬ê°œ)
        existing_cache = None
        if use_gemini_cache and os.path.exists(gemini_cache_path):
            try:
                existing_cache = load_gemini_cache(gemini_cache_path)
                if existing_cache and len(existing_cache) > 0:
                    print(f"ê¸°ì¡´ ìºì‹œ ë°œê²¬: {len(existing_cache)}ê°œ í˜ì´ì§€. ì¬ê°œí•©ë‹ˆë‹¤...")
                    page_jsons = existing_cache.copy()
            except Exception as e:
                print(f"ê¸°ì¡´ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}. ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
        
        # ê° í˜ì´ì§€ íŒŒì‹± (ì´ë¯¸ íŒŒì‹±ëœ í˜ì´ì§€ëŠ” ìŠ¤í‚µ)
        start_idx = len(page_jsons)
        total_parse_time = 0.0
        
        # í˜ì´ì§€ ìˆ˜ê°€ ì¶©ë¶„íˆ ë§ì„ ë•Œë§Œ ë©€í‹°ìŠ¤ë ˆë”© ì‚¬ìš© (ì˜¤ë²„í—¤ë“œ ê³ ë ¤)
        use_parallel = (len(images) - start_idx) > 1
        
        if use_parallel:
            # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ë³‘ë ¬ íŒŒì‹±
            cache_lock = Lock()  # ìºì‹œ ì €ì¥ ì‹œ ë™ê¸°í™”ìš©
            completed_count = 0  # ì™„ë£Œëœ í˜ì´ì§€ ìˆ˜ ì¶”ì 
            results_lock = Lock()  # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì‹œ ë™ê¸°í™”ìš©
            
            def parse_single_page(idx: int) -> tuple[int, Dict[str, Any], float, Optional[str]]:
                """ë‹¨ì¼ í˜ì´ì§€ íŒŒì‹± í•¨ìˆ˜ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰) - ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë³„ë„ì˜ íŒŒì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
                parse_start_time = time.time()
                try:
                    # ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë³„ë„ì˜ íŒŒì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (thread-safe)
                    thread_parser = GeminiVisionParser(api_key=gemini_api_key, model_name=gemini_model)
                    page_json = thread_parser.parse_image(images[idx])  # ê° í˜ì´ì§€ íŒŒì‹±
                    parse_end_time = time.time()
                    parse_duration = parse_end_time - parse_start_time
                    return (idx, page_json, parse_duration, None)
                except Exception as e:
                    parse_end_time = time.time()
                    parse_duration = parse_end_time - parse_start_time
                    error_result = {"text": f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}", "error": True}
                    return (idx, error_result, parse_duration, str(e))
            
            # ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 5ê°œ ìŠ¤ë ˆë“œ)
            max_workers = min(5, len(images) - start_idx)  # ìµœëŒ€ 5ê°œ ìŠ¤ë ˆë“œ ë˜ëŠ” ë‚¨ì€ í˜ì´ì§€ ìˆ˜ ì¤‘ ì‘ì€ ê°’
            print(f"ğŸš€ ë©€í‹°ìŠ¤ë ˆë”© íŒŒì‹± ì‹œì‘ (ìµœëŒ€ {max_workers}ê°œ ìŠ¤ë ˆë“œ)")
            
            # ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ (ì¸ë±ìŠ¤ ìˆœì„œ ë³´ì¥)
            parsed_results = {}
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # ëª¨ë“  í˜ì´ì§€ì— ëŒ€í•´ Future ì œì¶œ
                future_to_idx = {
                    executor.submit(parse_single_page, idx): idx 
                    for idx in range(start_idx, len(images))
                }
                
                # ì™„ë£Œëœ ì‘ì—…ë¶€í„° ì²˜ë¦¬
                for future in as_completed(future_to_idx):
                    idx, page_json, parse_duration, error = future.result()
                    total_parse_time += parse_duration
                    
                    # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥ (ì¸ë±ìŠ¤ ìˆœì„œ ë³´ì¥)
                    with results_lock:
                        parsed_results[idx] = page_json
                        completed_count += 1
                    
                    # ì§„í–‰ ìƒí™© ì¶œë ¥
                    if error:
                        print(f"í˜ì´ì§€ {idx+1}/{len(images)} íŒŒì‹± ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {parse_duration:.2f}ì´ˆ) - {error}")
                    else:
                        print(f"í˜ì´ì§€ {idx+1}/{len(images)} íŒŒì‹± ì™„ë£Œ (ì†Œìš” ì‹œê°„: {parse_duration:.2f}ì´ˆ) [{completed_count}/{len(images) - start_idx}]")
                    
                    # ê° í˜ì´ì§€ íŒŒì‹± í›„ ì¦‰ì‹œ ìºì‹œì— ì €ì¥ (ë™ê¸°í™” í•„ìš”)
                    if use_gemini_cache:
                        try:
                            with results_lock:
                                # í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ë¥¼ ì„ì‹œ ë¦¬ìŠ¤íŠ¸ì— ë°˜ì˜
                                temp_page_jsons = list(page_jsons)  # ê¸°ì¡´ ë°ì´í„° ë³µì‚¬
                                for result_idx in sorted(parsed_results.keys()):
                                    if result_idx < len(temp_page_jsons):
                                        temp_page_jsons[result_idx] = parsed_results[result_idx]
                                    else:
                                        # ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ë§ì¶”ê¸° ìœ„í•´ Noneìœ¼ë¡œ ì±„ìš´ í›„ ì¶”ê°€
                                        while len(temp_page_jsons) < result_idx:
                                            temp_page_jsons.append(None)
                                        temp_page_jsons.append(parsed_results[result_idx])
                            
                            with cache_lock:  # ìºì‹œ ì €ì¥ ë™ê¸°í™”
                                # Noneì„ ì œê±°í•˜ì§€ ì•Šê³  ì €ì¥ (ì¸ë±ìŠ¤ ìˆœì„œ ìœ ì§€)
                                save_gemini_cache(gemini_cache_path, temp_page_jsons)  # ì¦‰ì‹œ ì €ì¥
                        except Exception as e:
                            print(f"  âš ï¸ í˜ì´ì§€ {idx+1} ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            # ìµœì¢… ê²°ê³¼ë¥¼ ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ page_jsonsì— ë°˜ì˜
            for idx in range(start_idx, len(images)):
                if idx in parsed_results:
                    if idx < len(page_jsons):
                        page_jsons[idx] = parsed_results[idx]  # ì—…ë°ì´íŠ¸
                    else:
                        # ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ë§ì¶”ê¸° ìœ„í•´ Noneìœ¼ë¡œ ì±„ìš´ í›„ ì¶”ê°€
                        while len(page_jsons) < idx:
                            page_jsons.append(None)
                        page_jsons.append(parsed_results[idx])  # ì¶”ê°€
            
        else:
            # ë‹¨ì¼ í˜ì´ì§€ì¸ ê²½ìš° ìˆœì°¨ ì²˜ë¦¬
            for idx in range(start_idx, len(images)):
                parse_start_time = time.time()  # íŒŒì‹± ì‹œê°„ ì¸¡ì • ì‹œì‘
                try:
                    print(f"í˜ì´ì§€ {idx+1}/{len(images)} Gemini Vision íŒŒì‹± ì¤‘...", end="", flush=True)
                    
                    page_json = gemini_parser.parse_image(images[idx])  # ê° í˜ì´ì§€ íŒŒì‹±
                    parse_end_time = time.time()
                    parse_duration = parse_end_time - parse_start_time
                    total_parse_time += parse_duration
                    
                    # í˜ì´ì§€ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€/ì—…ë°ì´íŠ¸
                    if idx < len(page_jsons):
                        page_jsons[idx] = page_json  # ì—…ë°ì´íŠ¸
                    else:
                        page_jsons.append(page_json)  # ì¶”ê°€
                    
                    # íŒŒì‹± ì‹œê°„ ì¶œë ¥
                    print(f" ì™„ë£Œ (ì†Œìš” ì‹œê°„: {parse_duration:.2f}ì´ˆ)")
                    
                    # ê° í˜ì´ì§€ íŒŒì‹± í›„ ì¦‰ì‹œ ìºì‹œì— ì €ì¥ (ì¤‘ê°„ì— ì‹¤íŒ¨í•´ë„ ì†ì‹¤ ë°©ì§€)
                    if use_gemini_cache:
                        try:
                            print(f"  ğŸ’¾ í˜ì´ì§€ {idx+1} ìºì‹œ ì €ì¥ ì‹œë„ ì¤‘...", end="", flush=True)
                            save_gemini_cache(gemini_cache_path, page_jsons)  # ì¦‰ì‹œ ì €ì¥
                        except Exception as e:
                            print(f"\n  âš ï¸ í˜ì´ì§€ {idx+1} ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
                            import traceback
                            traceback.print_exc()
                    
                except Exception as e:
                    parse_end_time = time.time()
                    parse_duration = parse_end_time - parse_start_time
                    total_parse_time += parse_duration
                    print(f" ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {parse_duration:.2f}ì´ˆ) - {e}")
                    # ì‹¤íŒ¨í•œ í˜ì´ì§€ëŠ” ë¹ˆ ê²°ê³¼ë¡œ ì¶”ê°€ (ë‚˜ì¤‘ì— ì¬ì‹œë„ ê°€ëŠ¥)
                    if idx >= len(page_jsons):
                        page_jsons.append({"text": f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}", "error": True})
                    # ì‹¤íŒ¨í•´ë„ ìºì‹œëŠ” ì €ì¥ (ë¶€ë¶„ ê²°ê³¼ë¼ë„ ë³´ì¡´)
                    if use_gemini_cache:
                        try:
                            save_gemini_cache(gemini_cache_path, page_jsons)
                        except:
                            pass
                    # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                    continue
        
        # ì „ì²´ íŒŒì‹± ì‹œê°„ ìš”ì•½ ì¶œë ¥
        if start_idx < len(images):
            parsed_count = len(images) - start_idx
            avg_time = total_parse_time / parsed_count if parsed_count > 0 else 0
            print(f"\nğŸ“Š íŒŒì‹± í†µê³„:")
            print(f"  - ìƒˆë¡œ íŒŒì‹±í•œ í˜ì´ì§€: {parsed_count}ê°œ")
            print(f"  - ì´ ì†Œìš” ì‹œê°„: {total_parse_time:.2f}ì´ˆ")
            print(f"  - í‰ê·  í˜ì´ì§€ë‹¹ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            if start_idx > 0:
                print(f"  - ìºì‹œì—ì„œ ë¡œë“œí•œ í˜ì´ì§€: {start_idx}ê°œ")
    
    # ì´ë¯¸ì§€ ê²½ë¡œê°€ ë¹„ì–´ìˆìœ¼ë©´ ìƒì„± (ìºì‹œì—ì„œ ë¡œë“œí•œ ê²½ìš°)
    if not image_paths and save_images:
        # ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
        if os.path.exists(abs_image_dir):
            for idx in range(len(page_jsons)):
                img_path = os.path.join(abs_image_dir, f"page_{idx+1}.png")
                if os.path.exists(img_path):
                    image_paths.append(img_path)
                else:
                    image_paths.append(None)
        else:
            image_paths = [None] * len(page_jsons) if page_jsons else []
    
    return page_jsons, image_paths

